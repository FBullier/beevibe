{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDY7mUu58FMN"
      },
      "source": [
        "# Beevibe - Binary tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK7ydTAYYZB-"
      },
      "source": [
        "## Manage Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ApCvyV9YeHD"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGBhyWkpZ4uG",
        "outputId": "88931044-f9b0-4ef5-a5e8-2c32d427ed9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-bkazmkfq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-bkazmkfq\n",
            "  Resolved https://github.com/huggingface/transformers to commit 62db3e6ed67a74cc1ed1436acd9973915c0a4475\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (2024.12.14)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.49.0.dev0-py3-none-any.whl size=10627237 sha256=71d9670d0164a0101591d94947c94e26517d29711671bb5b94704b26414e6b1d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d8fcvk1u/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "Successfully installed transformers-4.49.0.dev0\n"
          ]
        }
      ],
      "source": [
        "# Get the last Transformers version for ModernBert\n",
        "! pip install git+https://github.com/huggingface/transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY9BHVb9YhcF"
      },
      "outputs": [],
      "source": [
        "# Installe Beevibe 0.13 from Pippy Test\n",
        "! pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ beevibe==0.1.0.dev13 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzkYGZkLYxTj",
        "outputId": "4c4f7801-9526-47d6-fa3c-76cf65807cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install watermark --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXry0w1PHBCK"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Xcs71pBHRzk"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import numpy as np\n",
        "from watermark import watermark\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from beevibe import BeeTrainer, BeeMLMClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQz8AcJaG7pJ"
      },
      "source": [
        "## GPU Card"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5ytYfftGWuJ",
        "outputId": "2abfaf62-4b86-4345-c4a9-699135676746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb  2 16:07:35 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRejiKEqvn7t"
      },
      "source": [
        "## Drive Directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX6wUJrOeJnS"
      },
      "outputs": [],
      "source": [
        "# Path sur le projet\n",
        "sys.path.insert(0, \"..\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjQyB_F7CyPT"
      },
      "source": [
        "## Packages versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jARbtmvuCR50",
        "outputId": "6c4a3c56-7aa6-4179-9d37-d1bd53dcd0f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last updated: 2025-02-02T16:07:35.273874+00:00\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.11.11\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 6.1.85+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 8\n",
            "Architecture: 64bit\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(watermark())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maanWhDACXBD",
        "outputId": "0b22a843-0900-470e-cdfc-b3fd450160e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pandas       : 2.2.2\n",
            "numpy        : 1.26.4\n",
            "scipy        : 1.13.1\n",
            "sklearn      : 1.6.1\n",
            "torch        : 2.5.1+cu124\n",
            "transformers : 4.49.0.dev0\n",
            "tokenizers   : 0.21.0\n",
            "sentencepiece: 0.2.0\n",
            "datasets     : 3.2.0\n",
            "beevibe      : 0.1.0.dev13\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(watermark(packages=\"pandas,numpy,scipy,sklearn,torch,transformers,tokenizers,sentencepiece,datasets,beevibe\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSR2ozK1vkz8"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KGoHUaCYZCB"
      },
      "source": [
        "### Get Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "fe4962fa766c4bee98e3058968d59091",
            "2a072f14a6a14446a2a67c6bb4c2ef28",
            "3037a2227def41f6a7e9e567225249bf",
            "4840621a4bcd46fc99f6b98d51df3ad5",
            "86995c1bfb1c4d4daf9fe51f61f923ed",
            "0ee8a8df6d204056a5f2c617cb320efb",
            "21a1f27fac834c01b6d23347f7452375",
            "a0f7505674654f839165572649944883",
            "4f497597b5a344dcb9f9cd76817e7a6c",
            "76bbf3d0e2ff435b97b7f91dc7a9857a",
            "8a84105e62b04ab9b89bc62e2ebcf86c",
            "ed7147ceb27748189b02f9c84b405bb5",
            "16130cde324543b2879a185200213902",
            "a9f70c65e83e4dc4b6601161541c9bbb",
            "5a0320a475a244779bf9e2e40aa44405",
            "e8f358fb22a943f78e69ce1a1aeb7c1b",
            "69a75368ae69463da88e63700b301d44",
            "8b8cb0263e1342f4bafbbd80a0873142",
            "2a07fd2aafb94f289b8d8fed15debd99",
            "c90ae4958bd24f35b0ce9db6fd3cc7d9",
            "60e8d4a4719840ba971add9bd5dd9fee",
            "fe3eadd4a3424596a00fdd4cc8324baa"
          ]
        },
        "id": "KqlBsFEqpHfl",
        "outputId": "864adff6-b333-4c34-a510-e85294666096"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe4962fa766c4bee98e3058968d59091",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed7147ceb27748189b02f9c84b405bb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"train\": \"elegana_train_v0_1.csv\",\n",
        "    \"test\": \"elegana_test_v0_1.csv\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"Franbul/elegana_relation_client_FR\",\n",
        "    data_files=data_files,\n",
        "    sep=\"|\")\n",
        "\n",
        "pd_train = dataset[\"train\"].to_pandas()\n",
        "pd_test = dataset[\"test\"].to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJbC5wKnYZCB"
      },
      "source": [
        "### Get Themes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c1c2bd1ccb1b428586f7235f6aa6f2de",
            "16d0472af01148ffbe2660f65c2cc2ee",
            "4542439f976244d48ce7dd3e927baa47",
            "5a870e0b3280444d89b026d1feb708d9",
            "573ea5e66b404d788ce0b877ee98a5f4",
            "9412f473d59142bc8adea6bb9b9387e2",
            "fa0c5d009ab44f9f886724a0023d8271",
            "10477fe81ecf413eab4533197e8e8b53",
            "9776da59b4df447e9bf955c1d8a40972",
            "c7995745374d42dbb1d7a78dab8428b5",
            "b813b77b9f6e4696829bad390a7641dd"
          ]
        },
        "id": "tBfEZNSDYZCB",
        "outputId": "0b9591c2-4f86-4deb-ad2a-2650f3791ce5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1c2bd1ccb1b428586f7235f6aa6f2de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating themes split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"themes\": \"elegana_themes_v0_1.csv\"\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"Franbul/elegana_relation_client_FR\",\n",
        "    data_files=data_files,\n",
        "    sep=\"|\")\n",
        "\n",
        "pd_themes = dataset[\"themes\"].to_pandas()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_9Fvvo5YZCB"
      },
      "source": [
        "### Merge datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_c9HmYHYZCB"
      },
      "outputs": [],
      "source": [
        "# Merge train, test and thems\n",
        "pd_data = pd.merge(pd_train, pd_themes, on=\"THEME\", how='left')\n",
        "pd_data_test = pd.merge(pd_test, pd_themes, on=\"THEME\", how='left')\n",
        "\n",
        "# Get a sample here\n",
        "#pd_data = pd_data.sample(200, random_state=1811)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CljMG0RYZCB",
        "outputId": "6f8a609d-e89f-43b2-de83-05094f67131b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2364, 10)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "jbajMkFcPQoh",
        "outputId": "67b59361-2c6a-4a83-e92e-aad1bfe149f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd_data\",\n  \"rows\": 2364,\n  \"fields\": [\n    {\n      \"column\": \"CLIENT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2124,\n        \"samples\": [\n          \"J'ai accidentellement command\\u00e9 deux fois le m\\u00eame chapeau. Pouvez-vous m'aider \\u00e0 annuler l'une des commandes ?\",\n          \"Organisez-vous des \\u00e9v\\u00e9nements pour promouvoir l'art et la culture ?\",\n          \"Les anses de mon sac se sont d\\u00e9tach\\u00e9es apr\\u00e8s une utilisation mod\\u00e9r\\u00e9e, ce n'est pas normal.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CONSEILLER\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2074,\n        \"samples\": [\n          \"Nous avons toujours des projets passionnants en cours avec de nouveaux artistes et designers. Pour \\u00eatre parmi les premiers \\u00e0 conna\\u00eetre nos futures collaborations, nous vous invitons \\u00e0 vous inscrire \\u00e0 notre newsletter ou \\u00e0 nous suivre sur les r\\u00e9seaux sociaux.\",\n          \"Je suis vraiment d\\u00e9sol\\u00e9 pour ce retard. Je vais v\\u00e9rifier imm\\u00e9diatement ce qui a pu se passer avec votre commande.\",\n          \"Bien s\\u00fbr, je suis l\\u00e0 pour vous aider. Pouvez-vous me dire quelles difficult\\u00e9s vous rencontrez? En g\\u00e9n\\u00e9ral, vous devez simplement entrer votre adresse email dans le champ pr\\u00e9vu \\u00e0 cet effet sur notre site et confirmer votre inscription en cliquant sur le lien que vous recevrez par email.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THEME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Questions sur la politique de retour\",\n          \"Probl\\u00e8mes de livraison internationale\",\n          \"Informations sur les limitations d'exp\\u00e9dition\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DESCRIPTION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Clarifications sur les conditions de retour.\",\n          \"Questions ou probl\\u00e8mes concernant la livraison hors du pays.\",\n          \"Restrictions ou limitations pour l'exp\\u00e9dition dans certaines r\\u00e9gions ou pays.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_CLASSES\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Support client op\\u00e9rationnel\",\n          \"Informations et services sp\\u00e9cialis\\u00e9s\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5_CLASSES\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Services exclusifs, programmes et personnalisations\",\n          \"Assistance technique et support imm\\u00e9diat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 63,\n        \"samples\": [\n          \"Combinaison\",\n          \"Facturation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"Remboursement\",\n          \"Caract\\u00e9ristique\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 81,\n        \"samples\": [\n          \"Assistance\",\n          \"Sp\\u00e9cifique\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"Produit\",\n          \"Demande\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "pd_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c4927d60-3877-4ed2-a068-28102f5d84d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLIENT</th>\n",
              "      <th>CONSEILLER</th>\n",
              "      <th>THEME</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>2_CLASSES</th>\n",
              "      <th>5_CLASSES</th>\n",
              "      <th>LABEL_1</th>\n",
              "      <th>LABEL_2</th>\n",
              "      <th>LABEL_3</th>\n",
              "      <th>LABEL_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Quelle est la taille de ce chapeau ?</td>\n",
              "      <td>La taille de ce chapeau est de 58 cm de circon...</td>\n",
              "      <td>Demande d'informations produit</td>\n",
              "      <td>Questions spécifiques sur les caractéristiques...</td>\n",
              "      <td>Informations et services spécialisés</td>\n",
              "      <td>Conseils et informations produits</td>\n",
              "      <td>Produit</td>\n",
              "      <td>Caractéristique</td>\n",
              "      <td>Spécifique</td>\n",
              "      <td>Demande</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Quels sont vos délais de livraison pour les co...</td>\n",
              "      <td>Nos délais de livraison pour les commandes en ...</td>\n",
              "      <td>Demande d'informations sur les achats en gros</td>\n",
              "      <td>Conditions et possibilités pour les achats en ...</td>\n",
              "      <td>Informations et services spécialisés</td>\n",
              "      <td>Services exclusifs, programmes et personnalisa...</td>\n",
              "      <td>Gros</td>\n",
              "      <td>Condition</td>\n",
              "      <td>Professionnel</td>\n",
              "      <td>Possibilité</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nous avons besoin de tenues pour un événement ...</td>\n",
              "      <td>Oui, en fonction du thème de l'événement, nous...</td>\n",
              "      <td>Demande de conseils pour les achats de groupe</td>\n",
              "      <td>Conseils pour effectuer des achats groupés (po...</td>\n",
              "      <td>Informations et services spécialisés</td>\n",
              "      <td>Conseils et informations produits</td>\n",
              "      <td>Achat</td>\n",
              "      <td>Groupe</td>\n",
              "      <td>Événement</td>\n",
              "      <td>Mariage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Le gilet que j'ai commandé est trop petit. Pui...</td>\n",
              "      <td>Je suis désolé d'apprendre que la taille du gi...</td>\n",
              "      <td>Échange de produit</td>\n",
              "      <td>Demande d'échange pour un autre taille, couleu...</td>\n",
              "      <td>Support client opérationnel</td>\n",
              "      <td>Commandes, livraison et suivi</td>\n",
              "      <td>Produit</td>\n",
              "      <td>Taille</td>\n",
              "      <td>Couleur</td>\n",
              "      <td>Option</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Est-ce que vous proposez des remises pour les ...</td>\n",
              "      <td>Oui, nous offrons des remises aux professionne...</td>\n",
              "      <td>Demande d'informations sur les achats en gros</td>\n",
              "      <td>Conditions et possibilités pour les achats en ...</td>\n",
              "      <td>Informations et services spécialisés</td>\n",
              "      <td>Services exclusifs, programmes et personnalisa...</td>\n",
              "      <td>Gros</td>\n",
              "      <td>Condition</td>\n",
              "      <td>Professionnel</td>\n",
              "      <td>Possibilité</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4927d60-3877-4ed2-a068-28102f5d84d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4927d60-3877-4ed2-a068-28102f5d84d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4927d60-3877-4ed2-a068-28102f5d84d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d3ad9dc-f16a-4d67-9356-903d1faf2519\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d3ad9dc-f16a-4d67-9356-903d1faf2519')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d3ad9dc-f16a-4d67-9356-903d1faf2519 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              CLIENT  \\\n",
              "0               Quelle est la taille de ce chapeau ?   \n",
              "1  Quels sont vos délais de livraison pour les co...   \n",
              "2  Nous avons besoin de tenues pour un événement ...   \n",
              "3  Le gilet que j'ai commandé est trop petit. Pui...   \n",
              "4  Est-ce que vous proposez des remises pour les ...   \n",
              "\n",
              "                                          CONSEILLER  \\\n",
              "0  La taille de ce chapeau est de 58 cm de circon...   \n",
              "1  Nos délais de livraison pour les commandes en ...   \n",
              "2  Oui, en fonction du thème de l'événement, nous...   \n",
              "3  Je suis désolé d'apprendre que la taille du gi...   \n",
              "4  Oui, nous offrons des remises aux professionne...   \n",
              "\n",
              "                                           THEME  \\\n",
              "0                 Demande d'informations produit   \n",
              "1  Demande d'informations sur les achats en gros   \n",
              "2  Demande de conseils pour les achats de groupe   \n",
              "3                             Échange de produit   \n",
              "4  Demande d'informations sur les achats en gros   \n",
              "\n",
              "                                         DESCRIPTION  \\\n",
              "0  Questions spécifiques sur les caractéristiques...   \n",
              "1  Conditions et possibilités pour les achats en ...   \n",
              "2  Conseils pour effectuer des achats groupés (po...   \n",
              "3  Demande d'échange pour un autre taille, couleu...   \n",
              "4  Conditions et possibilités pour les achats en ...   \n",
              "\n",
              "                              2_CLASSES  \\\n",
              "0  Informations et services spécialisés   \n",
              "1  Informations et services spécialisés   \n",
              "2  Informations et services spécialisés   \n",
              "3           Support client opérationnel   \n",
              "4  Informations et services spécialisés   \n",
              "\n",
              "                                           5_CLASSES  LABEL_1  \\\n",
              "0                  Conseils et informations produits  Produit   \n",
              "1  Services exclusifs, programmes et personnalisa...     Gros   \n",
              "2                  Conseils et informations produits    Achat   \n",
              "3                      Commandes, livraison et suivi  Produit   \n",
              "4  Services exclusifs, programmes et personnalisa...     Gros   \n",
              "\n",
              "           LABEL_2        LABEL_3      LABEL_4  \n",
              "0  Caractéristique     Spécifique      Demande  \n",
              "1        Condition  Professionnel  Possibilité  \n",
              "2           Groupe      Événement      Mariage  \n",
              "3           Taille        Couleur       Option  \n",
              "4        Condition  Professionnel  Possibilité  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XdFrFVLP9yj"
      },
      "source": [
        "### Get texts & labels for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "wI4fA2_pYZCC",
        "outputId": "aa1a9be4-f8af-43a2-afd4-aaccc8168ed6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_CLASSES</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Informations et services spécialisés</th>\n",
              "      <td>1629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support client opérationnel</th>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "2_CLASSES\n",
              "Informations et services spécialisés    1629\n",
              "Support client opérationnel              735\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd_data['2_CLASSES'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofsZ9bfKEo49",
        "outputId": "014820b4-416d-4d68-d235-a746cc83b524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train : Nb texts:2364, Nb labels:2364, Nb classes:2\n",
            "Test  : Nb texts:591, Nb labels:591, Nb classes:2\n"
          ]
        }
      ],
      "source": [
        "# Use THEME in 5-Classes for classification\n",
        "classes = np.unique(pd_data['2_CLASSES'])\n",
        "le_esg = LabelEncoder()\n",
        "le_esg.fit(classes)\n",
        "\n",
        "# Get sentences and labels to train\n",
        "labels_names = classes[le_esg.transform(classes)]\n",
        "labels = le_esg.transform(pd_data['2_CLASSES']).tolist()\n",
        "classes = np.unique(labels)\n",
        "texts = pd_data[\"CLIENT\"].values.tolist()\n",
        "print(f\"Train : Nb texts:{len(texts)}, Nb labels:{len(labels)}, Nb classes:{len(classes)}\")\n",
        "\n",
        "# Get sentences and labels to predict\n",
        "test_texts = pd_data_test[\"CLIENT\"].values.tolist()\n",
        "test_labels = le_esg.transform(pd_data_test['2_CLASSES']).tolist()\n",
        "print(f\"Test  : Nb texts:{len(test_texts)}, Nb labels:{len(test_labels)}, Nb classes:{len(np.unique(test_labels))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upF8CP1gYZCC"
      },
      "source": [
        "## Holdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC6RveVYYZCC"
      },
      "source": [
        "### camembert-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q07SV0BYZCC",
        "outputId": "34decbb8-6b10-45be-f5ad-1e916b937980"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Use optimizer : Adam\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.5328, Val Loss: 0.3725, Val MCC: 0.7017, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.2945, Val Loss: 0.2411, Val MCC: 0.8348, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.1922, Val Loss: 0.1900, Val MCC: 0.8649, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.1505, Val Loss: 0.1753, Val MCC: 0.8655, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.1119, Val Loss: 0.2032, Val MCC: 0.8657, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.0996, Val Loss: 0.1142, Val MCC: 0.9236, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.0669, Val Loss: 0.1160, Val MCC: 0.9201, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.0560, Val Loss: 0.1210, Val MCC: 0.9101, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.0451, Val Loss: 0.1081, Val MCC: 0.9142, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.0450, Val Loss: 0.1574, Val MCC: 0.8824, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.0543, Val Loss: 0.1262, Val MCC: 0.9164, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.0437, Val Loss: 0.1170, Val MCC: 0.9136, lr: 1.000e-05\n",
            "Best epoch: 8, Best loss: 0.1081\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9634\n",
            " - f1_macro: 0.9571\n",
            " - f1_micro: 0.9634\n",
            " - f1_weighted: 0.9634\n",
            " - mcc: 0.9142\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class          Precision      Recall          F1     Support\n",
            "Class 0           0.9755      0.9715      0.9735         492\n",
            "Class 1           0.9364      0.9450      0.9406         218\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "            Class 0  Class 1 \n",
            "Class 0     478      14    \n",
            "Class 1     12       206   \n",
            "Elapsed time: 00:10:09\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Create Classification Model\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"camembert-base\",\n",
        "    num_labels = num_labels,\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                    )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGTbUc-pQhR5"
      },
      "source": [
        "### camembertav2-base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1eVuO2pdK6q",
        "outputId": "dd3a59cd-e7e5-4318-e6d6-5dda5adcef97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Use optimizer : Adam\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.4886, Val Loss: 0.4939, Val MCC: 0.6011, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.2485, Val Loss: 0.2814, Val MCC: 0.7832, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.1581, Val Loss: 0.1787, Val MCC: 0.8557, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.0791, Val Loss: 0.1271, Val MCC: 0.9010, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.0628, Val Loss: 0.1529, Val MCC: 0.8938, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.0391, Val Loss: 0.1757, Val MCC: 0.8815, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.0314, Val Loss: 0.1775, Val MCC: 0.8834, lr: 1.000e-05\n",
            "Best epoch: 3, Best loss: 0.1271\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9577\n",
            " - f1_macro: 0.9505\n",
            " - f1_micro: 0.9577\n",
            " - f1_weighted: 0.9578\n",
            " - mcc: 0.9010\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class          Precision      Recall          F1     Support\n",
            "Class 0           0.9714      0.9675      0.9695         492\n",
            "Class 1           0.9273      0.9358      0.9315         218\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "            Class 0  Class 1 \n",
            "Class 0     476      16    \n",
            "Class 1     14       204   \n",
            "Elapsed time: 00:07:22\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Create Classification Model\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"almanach/camembertav2-base\",\n",
        "    num_labels = num_labels,\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                    )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYV3lHnecgBo"
      },
      "source": [
        "### ModernBERT-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_FZR2k9cglT",
        "outputId": "a8edcdeb-5c5b-4769-8446-1896092137fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Use optimizer : Adam\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.6853, Val Loss: 0.6278, Val MCC: 0.1190, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.4851, Val Loss: 0.3439, Val MCC: 0.7177, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.2688, Val Loss: 0.4197, Val MCC: 0.6229, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.1980, Val Loss: 0.3832, Val MCC: 0.6696, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.1193, Val Loss: 0.3511, Val MCC: 0.7050, lr: 1.000e-05\n",
            "Best epoch: 1, Best loss: 0.3439\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.8676\n",
            " - f1_macro: 0.8533\n",
            " - f1_micro: 0.8676\n",
            " - f1_weighted: 0.8710\n",
            " - mcc: 0.7177\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class          Precision      Recall          F1     Support\n",
            "Class 0           0.9523      0.8516      0.8991         492\n",
            "Class 1           0.7296      0.9037      0.8074         218\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "            Class 0  Class 1 \n",
            "Class 0     419      73    \n",
            "Class 1     21       197   \n",
            "Elapsed time: 00:07:01\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Create Classification Model\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"answerdotai/ModernBERT-base\",\n",
        "    num_labels = num_labels,\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                    )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMk0tOAbZaYG"
      },
      "source": [
        "### ModernBERT-Embed-BE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cs27Z5TZZks",
        "outputId": "98bda8ae-8028-48a8-9e97-8b2b84f4b786"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for Parallia/Fairly-Multilingual-ModernBERT-Embed-BE contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/Parallia/Fairly-Multilingual-ModernBERT-Embed-BE.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Use optimizer : Adam\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.4023, Val Loss: 0.2955, Val MCC: 0.7639, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.1589, Val Loss: 0.1642, Val MCC: 0.8782, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.0469, Val Loss: 0.1223, Val MCC: 0.9044, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.0168, Val Loss: 0.1295, Val MCC: 0.8798, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.0089, Val Loss: 0.1326, Val MCC: 0.9020, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.0188, Val Loss: 0.1330, Val MCC: 0.9059, lr: 1.000e-05\n",
            "Best epoch: 2, Best loss: 0.1223\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9592\n",
            " - f1_macro: 0.9522\n",
            " - f1_micro: 0.9592\n",
            " - f1_weighted: 0.9592\n",
            " - mcc: 0.9044\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class          Precision      Recall          F1     Support\n",
            "Class 0           0.9734      0.9675      0.9704         492\n",
            "Class 1           0.9276      0.9404      0.9339         218\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "            Class 0  Class 1 \n",
            "Class 0     476      16    \n",
            "Class 1     13       205   \n",
            "Elapsed time: 00:07:51\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Create Classification Model\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"Parallia/Fairly-Multilingual-ModernBERT-Embed-BE\",\n",
        "    num_labels = num_labels,\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                    )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWAxMxAeejrA"
      },
      "source": [
        "### ModernBERT-Embed-BE-FR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNIcvU_RZZQB",
        "outputId": "a0ffcf21-7c8a-4968-e851-2c47d33bc3d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Use optimizer : Adam\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.4924, Val Loss: 0.3909, Val MCC: 0.6552, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.2484, Val Loss: 0.2886, Val MCC: 0.7475, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.1430, Val Loss: 0.2317, Val MCC: 0.7894, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.0553, Val Loss: 0.1442, Val MCC: 0.8799, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.0418, Val Loss: 0.1419, Val MCC: 0.8975, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.0293, Val Loss: 0.1435, Val MCC: 0.9069, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.0154, Val Loss: 0.2048, Val MCC: 0.8878, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.0047, Val Loss: 0.1628, Val MCC: 0.9103, lr: 1.000e-05\n",
            "Best epoch: 4, Best loss: 0.1419\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9563\n",
            " - f1_macro: 0.9488\n",
            " - f1_micro: 0.9563\n",
            " - f1_weighted: 0.9564\n",
            " - mcc: 0.8975\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class          Precision      Recall          F1     Support\n",
            "Class 0           0.9695      0.9675      0.9685         492\n",
            "Class 1           0.9269      0.9312      0.9291         218\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "            Class 0  Class 1 \n",
            "Class 0     476      16    \n",
            "Class 1     15       203   \n",
            "Elapsed time: 00:11:02\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Create Classification Model\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"Parallia/Fairly-Multilingual-ModernBERT-Embed-BE-FR\",\n",
        "    num_labels = num_labels,\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                    )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyYa83EfS3dF"
      },
      "source": [
        "### distilcamembert-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0ZXUjyOTJjW",
        "outputId": "29a45b51-4429-4bca-a6ed-08051c321843"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Use optimizer : Adam\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.4851, Val Loss: 0.3733, Val MCC: 0.6838, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.2568, Val Loss: 0.2477, Val MCC: 0.7755, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.1588, Val Loss: 0.1545, Val MCC: 0.8878, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.1090, Val Loss: 0.1801, Val MCC: 0.8567, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.0786, Val Loss: 0.1426, Val MCC: 0.8957, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.0602, Val Loss: 0.1872, Val MCC: 0.8561, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.0442, Val Loss: 0.1283, Val MCC: 0.9105, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.0301, Val Loss: 0.1552, Val MCC: 0.9033, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.0294, Val Loss: 0.1392, Val MCC: 0.9041, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.0125, Val Loss: 0.1582, Val MCC: 0.9082, lr: 1.000e-05\n",
            "Best epoch: 6, Best loss: 0.1283\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9620\n",
            " - f1_macro: 0.9553\n",
            " - f1_micro: 0.9620\n",
            " - f1_weighted: 0.9619\n",
            " - mcc: 0.9105\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class          Precision      Recall          F1     Support\n",
            "Class 0           0.9716      0.9736      0.9726         492\n",
            "Class 1           0.9401      0.9358      0.9379         218\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "            Class 0  Class 1 \n",
            "Class 0     479      13    \n",
            "Class 1     14       204   \n",
            "Elapsed time: 00:04:45\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Create Classification Model\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"cmarkea/distilcamembert-base\",\n",
        "    num_labels = num_labels,\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                    )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HohRl1gJYZCD"
      },
      "source": [
        "#### Modify head and add AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsm1_UnYZCD",
        "outputId": "0073976a-26dc-47ac-afd0-a111e5914e28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.5381, Val Loss: 0.4064, Val MCC: 0.6387, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.3453, Val Loss: 0.2999, Val MCC: 0.7631, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.2393, Val Loss: 0.2141, Val MCC: 0.8196, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.1622, Val Loss: 0.1543, Val MCC: 0.8670, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.1104, Val Loss: 0.1318, Val MCC: 0.8951, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.0737, Val Loss: 0.1564, Val MCC: 0.8749, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.0482, Val Loss: 0.1259, Val MCC: 0.8969, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.0412, Val Loss: 0.1327, Val MCC: 0.9009, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.0368, Val Loss: 0.1562, Val MCC: 0.8857, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.0255, Val Loss: 0.1767, Val MCC: 0.8770, lr: 1.000e-05\n",
            "Best epoch: 6, Best loss: 0.1259\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9549\n",
            " - f1_macro: 0.9479\n",
            " - f1_micro: 0.9549\n",
            " - f1_weighted: 0.9553\n",
            " - mcc: 0.8969\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class                                       Precision      Recall          F1     Support\n",
            "Informations et services spécialisés           0.9812      0.9533      0.9670         492\n",
            "Support client opérationnel                    0.9009      0.9587      0.9289         218\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "                                         Informations et services spécialisés      Support client opérationnel      \n",
            "Informations et services spécialisés                   469                                    23                  \n",
            "Support client opérationnel                             9                                    209                  \n",
            "Elapsed time: 00:05:37\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Define a custom classification head\n",
        "head_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels},\n",
        "    ]\n",
        "\n",
        "# Create Classification Model from \"Camembert-base\"\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"cmarkea/distilcamembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=head_layer_configs\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                     labels_names=labels_names,\n",
        "                     optimizer_class=AdamW\n",
        "                     )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9arqXYHYZCD"
      },
      "source": [
        "#### Add a Lora configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yo2LrxYYZCD",
        "outputId": "3c7b8098-ee4a-44c3-d424-b1aece609a26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Using Lora\n",
            "Target modules : ['base_model.encoder.layer.0.attention.self.query', 'base_model.encoder.layer.0.attention.self.key', 'base_model.encoder.layer.0.attention.output.dense', 'base_model.encoder.layer.0.intermediate.dense', 'base_model.encoder.layer.0.output.dense', 'base_model.encoder.layer.1.attention.self.query', 'base_model.encoder.layer.1.attention.self.key', 'base_model.encoder.layer.1.attention.output.dense', 'base_model.encoder.layer.1.intermediate.dense', 'base_model.encoder.layer.1.output.dense', 'base_model.encoder.layer.2.attention.self.query', 'base_model.encoder.layer.2.attention.self.key', 'base_model.encoder.layer.2.attention.output.dense', 'base_model.encoder.layer.2.intermediate.dense', 'base_model.encoder.layer.2.output.dense', 'base_model.encoder.layer.3.attention.self.query', 'base_model.encoder.layer.3.attention.self.key', 'base_model.encoder.layer.3.attention.output.dense', 'base_model.encoder.layer.3.intermediate.dense', 'base_model.encoder.layer.3.output.dense', 'base_model.encoder.layer.4.attention.self.query', 'base_model.encoder.layer.4.attention.self.key', 'base_model.encoder.layer.4.attention.output.dense', 'base_model.encoder.layer.4.intermediate.dense', 'base_model.encoder.layer.4.output.dense', 'base_model.encoder.layer.5.attention.self.query', 'base_model.encoder.layer.5.attention.self.key', 'base_model.encoder.layer.5.attention.output.dense', 'base_model.encoder.layer.5.intermediate.dense', 'base_model.encoder.layer.5.output.dense', 'base_model.pooler.dense']\n",
            "trainable params: 5871108 || all params: 73965828 || trainable%: 7.937595182467233\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.6056, Val Loss: 0.5298, Val MCC: 0.5177, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.4779, Val Loss: 0.4465, Val MCC: 0.5699, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.4089, Val Loss: 0.3919, Val MCC: 0.6264, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.3494, Val Loss: 0.3621, Val MCC: 0.6939, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.2994, Val Loss: 0.3235, Val MCC: 0.7402, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.2641, Val Loss: 0.2799, Val MCC: 0.7670, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.2276, Val Loss: 0.2543, Val MCC: 0.7801, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.1969, Val Loss: 0.2450, Val MCC: 0.7895, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.1765, Val Loss: 0.2283, Val MCC: 0.8048, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.1561, Val Loss: 0.2164, Val MCC: 0.8209, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1358, Val Loss: 0.1801, Val MCC: 0.8351, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.1132, Val Loss: 0.1975, Val MCC: 0.8373, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.1080, Val Loss: 0.1833, Val MCC: 0.8488, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.0879, Val Loss: 0.1475, Val MCC: 0.8785, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.0800, Val Loss: 0.1411, Val MCC: 0.8842, lr: 1.000e-05\n",
            "Epoch 15/29, Train Loss: 0.0677, Val Loss: 0.1714, Val MCC: 0.8600, lr: 1.000e-05\n",
            "Epoch 16/29, Train Loss: 0.0578, Val Loss: 0.1635, Val MCC: 0.8719, lr: 1.000e-05\n",
            "Epoch 17/29, Train Loss: 0.0533, Val Loss: 0.2048, Val MCC: 0.8578, lr: 1.000e-05\n",
            "Best epoch: 14, Best loss: 0.1411\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9479\n",
            " - f1_macro: 0.9406\n",
            " - f1_micro: 0.9479\n",
            " - f1_weighted: 0.9486\n",
            " - mcc: 0.8842\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class                                       Precision      Recall          F1     Support\n",
            "Informations et services spécialisés           0.9872      0.9370      0.9614         492\n",
            "Support client opérationnel                    0.8724      0.9725      0.9197         218\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "                                         Informations et services spécialisés      Support client opérationnel      \n",
            "Informations et services spécialisés                   461                                    31                  \n",
            "Support client opérationnel                             6                                    212                  \n",
            "Elapsed time: 00:08:37\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Define a custom classification head\n",
        "head_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels},\n",
        "    ]\n",
        "\n",
        "# Create Classification Model\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"cmarkea/distilcamembert-base\", #\"camembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=head_layer_configs\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                            labels_names=labels_names,\n",
        "                            optimizer_class=AdamW,\n",
        "                            use_lora=True,\n",
        "                            lora_r = 64,\n",
        "                            lora_alpha= 128,\n",
        "                            lora_dropout = 0.01,\n",
        "                            )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dVDU_rhxpPQ"
      },
      "source": [
        "#### Try multiple heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A7D-BVAxwZn"
      },
      "outputs": [],
      "source": [
        "# Large list of possible classification heads\n",
        "\n",
        "heads_network_patterns = [\n",
        "\n",
        "    # Pattern 0: One layer Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 1: Basic Feedforward Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 2: Shallow Network with Dropout\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 256, \"activation\": nn.ReLU, \"dropout_rate\": 0.2},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 3: Batch-Normalized Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 4: Wide Hidden Layers\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 1024, \"activation\": nn.GELU},\n",
        "        {\"input_size\": 1024, \"output_size\": 512, \"activation\": nn.GELU},\n",
        "        {\"input_size\": 512, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 5: Layer Normalization\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 6: Minimalistic Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 128, \"activation\": nn.Tanh},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 7: Deep Feedforward Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 8: Dropout Regularization\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"dropout_rate\": 0.4},\n",
        "        {\"input_size\": 512, \"output_size\": 128, \"activation\": nn.ReLU, \"dropout_rate\": 0.4},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 9: Deep Residual Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"residual\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 512, \"activation\": nn.ReLU, \"residual\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"residual\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 10: Compact Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 64, \"activation\": nn.SiLU},\n",
        "        {\"input_size\": 64, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 11: Fully Connected Bottleneck Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 12: Dense Network with No Activation in Final Layer\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 13: Layer Normalization with High Dropout\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True, \"dropout_rate\": 0.5},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU, \"layer_norm\": True, \"dropout_rate\": 0.5},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 14: Gated Activation with Dropout\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.GELU, \"dropout_rate\": 0.2},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.SiLU},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 15: Progressive Layer Expansion\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 16: Deep Wide Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 1024, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 1024, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 17: Dense Residual Network with Skip Connections\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 768, \"activation\": nn.ReLU, \"residual\": True},\n",
        "        {\"input_size\": 768, \"output_size\": 768, \"activation\": nn.ReLU, \"residual\": True},\n",
        "        {\"input_size\": 768, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 18: Alternating Normalization\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 19: Advanced Progressive Shrinkage\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 20: Feature Extractor with Sparse Hidden Units\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 64, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 64, \"output_size\": 32, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 32, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 21: Multi-Layer Sparse Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": 64, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 64, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 22: Alternating Dropout Intensities\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"dropout_rate\": 0.2},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"dropout_rate\": 0.5},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU, \"dropout_rate\": 0.3},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 23: High-Dimensional Bottleneck with Residuals\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 1024, \"activation\": nn.GELU, \"residual\": True},\n",
        "        {\"input_size\": 1024, \"output_size\": 256, \"activation\": nn.GELU, \"residual\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 24: Fully Dense Network with Gradient Clipping\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 1024, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 1024, \"output_size\": 1024, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 1024, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 25: Deeply Layer-Normalized Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 26: Modular Feedforward Blocks\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 27: High-Frequency Regularization Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"dropout_rate\": 0.1},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"dropout_rate\": 0.1},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU, \"dropout_rate\": 0.1},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 28: Alternating Activations Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.SiLU},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.GELU},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 29: Sequential Dropout and Bottleneck\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"dropout_rate\": 0.4},\n",
        "        {\"input_size\": 512, \"output_size\": 128, \"activation\": nn.ReLU, \"dropout_rate\": 0.4},\n",
        "        {\"input_size\": 128, \"output_size\": 64, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 64, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 30: Multi-Head Modular Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 31: Sparse Progressive Expansion\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 32: Residual Shrinking Layers\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.GELU, \"residual\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.GELU, \"residual\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 33: Dual Activation Fusion\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.SiLU},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.GELU},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 34: Deeply Narrow Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 128, \"activation\": nn.Tanh},\n",
        "        {\"input_size\": 128, \"output_size\": 64, \"activation\": nn.Tanh},\n",
        "        {\"input_size\": 64, \"output_size\": 32, \"activation\": nn.Tanh},\n",
        "        {\"input_size\": 32, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 35: Cyclic Dropout Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 256, \"activation\": nn.ReLU, \"dropout_rate\": 0.2},\n",
        "        {\"input_size\": 256, \"output_size\": 256, \"activation\": nn.ReLU, \"dropout_rate\": 0.4},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 36: Wide Bottleneck Layers\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 1024, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 1024, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 1024, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 1024, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 37: Alternating Sparse Connectivity\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 38: Progressive Layer Normalization\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 39: Activation Modulated Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.GELU},\n",
        "        {\"input_size\": 128, \"output_size\": 64, \"activation\": nn.Tanh},\n",
        "        {\"input_size\": 64, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 40: Double Residual Connections\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"residual\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"residual\": True},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 41: Dense Alternating Widths\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 1024, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 1024, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 42: Multi-Normalization Layers\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 43: Sparse Expansion with Skip\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 64, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 64, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 64, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 64, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 44: Mixed Activations Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.SiLU},\n",
        "        {\"input_size\": 512, \"output_size\": 128, \"activation\": nn.GELU},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 45: Dense Shallow Layers\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 46: Split-and-Merge Architecture\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 47: Gradient Clipping Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 1024, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 1024, \"output_size\": 1024, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 1024, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 48: High-Dropout Bottleneck\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"dropout_rate\": 0.5},\n",
        "        {\"input_size\": 512, \"output_size\": 128, \"activation\": nn.ReLU, \"dropout_rate\": 0.5},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 49: Alternating Nonlinearities\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": 128, \"activation\": nn.Tanh},\n",
        "        {\"input_size\": 128, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "    # Pattern 50: Wide-to-Narrow Progressive Network\n",
        "    [\n",
        "        {\"input_size\": 768, \"output_size\": 1024, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 1024, \"output_size\": 512, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels, \"activation\": None},\n",
        "    ],\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPdZxKmIyYdL",
        "outputId": "fc6baebe-3934-4c1b-b9ff-54eadcce1547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pattern 0\n",
            "  - MCC: 0.8664800576874168\n",
            "\n",
            "Pattern 1\n",
            "  - MCC: 0.8915078506582653\n",
            "\n",
            "Pattern 2\n",
            "  - MCC: 0.8989510600044248\n",
            "\n",
            "Pattern 3\n",
            "  - MCC: 0.901526932729356\n",
            "\n",
            "Pattern 4\n",
            "  - MCC: 0.8245886564924707\n",
            "\n",
            "Pattern 5\n",
            "  - MCC: 0.9094196874538816\n",
            "\n",
            "Pattern 6\n",
            "  - MCC: 0.8593536848714783\n",
            "\n",
            "Pattern 7\n",
            "  - MCC: 0.831353776399996\n",
            "\n",
            "Pattern 8\n",
            "  - MCC: 0.8600392775817288\n",
            "\n",
            "Pattern 9\n",
            "  - MCC: 0.8310210716550828\n",
            "\n",
            "Pattern 10\n",
            "  - MCC: 0.8974157269985179\n",
            "\n",
            "Pattern 11\n",
            "  - MCC: 0.8714323175633598\n",
            "\n",
            "Pattern 12\n",
            "  - MCC: 0.8791926307378476\n",
            "\n",
            "Pattern 13\n",
            "  - MCC: 0.8466672558728766\n",
            "\n",
            "Pattern 14\n",
            "  - MCC: 0.8209634920219804\n",
            "\n",
            "Pattern 15\n",
            "  - MCC: 0.8597878237468666\n",
            "\n",
            "Pattern 16\n",
            "  - MCC: 0.8858564957148359\n",
            "\n",
            "Pattern 17\n",
            "  - MCC: 0.8451189122501\n",
            "\n",
            "Pattern 18\n",
            "  - MCC: 0.8577746624335467\n",
            "\n",
            "Pattern 19\n",
            "  - MCC: 0.831353776399996\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Try the first 20 heads\n",
        "nb_first_heads = 20\n",
        "\n",
        "# Trainer parameters\n",
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Save results\n",
        "save_results = []\n",
        "\n",
        "# Try different heads\n",
        "for i, head_network_pattern in enumerate(heads_network_patterns[:nb_first_heads]):\n",
        "\n",
        "  print(f\"Pattern {i}\")\n",
        "\n",
        "  # Create Classification Model\n",
        "  model = BeeMLMClassifier(\n",
        "      model_name = \"cmarkea/distilcamembert-base\",\n",
        "      num_labels = num_labels,\n",
        "      head_layers=head_network_pattern\n",
        "  )\n",
        "\n",
        "  # Create Trainer with Lora parameters\n",
        "  trainer = BeeTrainer(model=model,\n",
        "                              labels_names=labels_names,\n",
        "                              optimizer_class=AdamW,\n",
        "                              use_lora=True,\n",
        "                              lora_r = 64,\n",
        "                              lora_alpha= 128,\n",
        "                              lora_dropout = 0.01,\n",
        "                              verbose=False\n",
        "                              )\n",
        "\n",
        "  # Train over a Holdout with Earlystopping\n",
        "  ret = trainer.holdout(texts=texts,\n",
        "                      labels=labels,\n",
        "                      val_size=val_size,\n",
        "                      num_epochs=num_epochs,\n",
        "                      batch_size=batch_size,\n",
        "                      patience=patience,\n",
        "                      min_delta=min_delta,\n",
        "                      balanced=True\n",
        "                      )\n",
        "\n",
        "  print(f\"  - MCC: {ret.get('val_metrics')[-1].get('mcc')}\\n\")\n",
        "\n",
        "  save_results.append(ret)\n",
        "\n",
        "  # Free CPU/GPU memory\n",
        "  trainer.release_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTAimwQykB82",
        "outputId": "bd30298f-914e-482b-9bcf-6fe33665b5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best pattern : \n",
            "[{'input_size': 768, 'output_size': 256, 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'layer_norm': True}, {'input_size': 256, 'output_size': 128, 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'layer_norm': True}, {'input_size': 128, 'output_size': 2, 'activation': None}]\n",
            "MCC:0.9094196874538816\n"
          ]
        }
      ],
      "source": [
        "pattern_index = np.argmax([k.get('val_metrics')[-1].get('mcc') for k in save_results])\n",
        "pattern_mcc = save_results[pattern_index].get('val_metrics')[-1].get('mcc')\n",
        "print(\"Best pattern : \")\n",
        "print(heads_network_patterns[pattern_index])\n",
        "print(f\"MCC:{pattern_mcc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzbVFTMUlLbA",
        "outputId": "1382b20d-d271-4138-aae8-81849af96af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 0 pattern\n",
            "Best pattern : \n",
            "[{'input_size': 768, 'output_size': 256, 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'layer_norm': True}, {'input_size': 256, 'output_size': 128, 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'layer_norm': True}, {'input_size': 128, 'output_size': 2, 'activation': None}]\n",
            "MCC:0.9094196874538816\n",
            "\n",
            "\n",
            "Top 1 pattern\n",
            "Best pattern : \n",
            "[{'input_size': 768, 'output_size': 512, 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batch_norm': True}, {'input_size': 512, 'output_size': 256, 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batch_norm': True}, {'input_size': 256, 'output_size': 2, 'activation': None}]\n",
            "MCC:0.901526932729356\n",
            "\n",
            "\n",
            "Top 2 pattern\n",
            "Best pattern : \n",
            "[{'input_size': 768, 'output_size': 256, 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'dropout_rate': 0.2}, {'input_size': 256, 'output_size': 2, 'activation': None}]\n",
            "MCC:0.8989510600044248\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "arr = np.array([k.get('val_metrics')[-1].get('mcc') for k in save_results])\n",
        "sorted_indexes = np.argsort(arr)[::-1]\n",
        "top_3_indexes = sorted_indexes[:3]\n",
        "\n",
        "for i, ind in enumerate(top_3_indexes):\n",
        "  print(f\"Top {i} pattern\")\n",
        "  pattern_mcc = save_results[ind].get('val_metrics')[-1].get('mcc')\n",
        "  print(\"Best pattern : \")\n",
        "  print(heads_network_patterns[ind])\n",
        "  print(f\"MCC:{pattern_mcc}\")\n",
        "  print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTWZRBmLYZCE"
      },
      "source": [
        "## Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPzP053cYZCE",
        "outputId": "0830a7ad-6c37-43ff-be41-64998ae8d435"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "\n",
            "\n",
            "> Fold 1\n",
            "Using Lora\n",
            "Target modules : ['base_model.encoder.layer.0.attention.self.query', 'base_model.encoder.layer.0.attention.self.key', 'base_model.encoder.layer.0.attention.output.dense', 'base_model.encoder.layer.0.intermediate.dense', 'base_model.encoder.layer.0.output.dense', 'base_model.encoder.layer.1.attention.self.query', 'base_model.encoder.layer.1.attention.self.key', 'base_model.encoder.layer.1.attention.output.dense', 'base_model.encoder.layer.1.intermediate.dense', 'base_model.encoder.layer.1.output.dense', 'base_model.encoder.layer.2.attention.self.query', 'base_model.encoder.layer.2.attention.self.key', 'base_model.encoder.layer.2.attention.output.dense', 'base_model.encoder.layer.2.intermediate.dense', 'base_model.encoder.layer.2.output.dense', 'base_model.encoder.layer.3.attention.self.query', 'base_model.encoder.layer.3.attention.self.key', 'base_model.encoder.layer.3.attention.output.dense', 'base_model.encoder.layer.3.intermediate.dense', 'base_model.encoder.layer.3.output.dense', 'base_model.encoder.layer.4.attention.self.query', 'base_model.encoder.layer.4.attention.self.key', 'base_model.encoder.layer.4.attention.output.dense', 'base_model.encoder.layer.4.intermediate.dense', 'base_model.encoder.layer.4.output.dense', 'base_model.encoder.layer.5.attention.self.query', 'base_model.encoder.layer.5.attention.self.key', 'base_model.encoder.layer.5.attention.output.dense', 'base_model.encoder.layer.5.intermediate.dense', 'base_model.encoder.layer.5.output.dense', 'base_model.pooler.dense']\n",
            "trainable params: 5871108 || all params: 73965828 || trainable%: 7.937595182467233\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.6037, Val Loss: 0.4866, Val MCC: 0.5185, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.4613, Val Loss: 0.4227, Val MCC: 0.5802, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.3912, Val Loss: 0.3688, Val MCC: 0.6572, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.3335, Val Loss: 0.3222, Val MCC: 0.7286, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.2858, Val Loss: 0.2900, Val MCC: 0.7650, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.2523, Val Loss: 0.2668, Val MCC: 0.7928, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.2155, Val Loss: 0.2493, Val MCC: 0.8059, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.1861, Val Loss: 0.2359, Val MCC: 0.8191, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.1573, Val Loss: 0.2417, Val MCC: 0.8191, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.1373, Val Loss: 0.2405, Val MCC: 0.8115, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1145, Val Loss: 0.2408, Val MCC: 0.8135, lr: 1.000e-05\n",
            "Best epoch: 7, Best loss: 0.2359\n",
            "\n",
            "\n",
            "> Fold 2\n",
            "Using Lora\n",
            "Target modules : ['roberta.encoder.layer.0.attention.self.query', 'roberta.encoder.layer.0.attention.self.key', 'roberta.encoder.layer.0.attention.output.dense', 'roberta.encoder.layer.0.intermediate.dense', 'roberta.encoder.layer.0.output.dense', 'roberta.encoder.layer.1.attention.self.query', 'roberta.encoder.layer.1.attention.self.key', 'roberta.encoder.layer.1.attention.output.dense', 'roberta.encoder.layer.1.intermediate.dense', 'roberta.encoder.layer.1.output.dense', 'roberta.encoder.layer.2.attention.self.query', 'roberta.encoder.layer.2.attention.self.key', 'roberta.encoder.layer.2.attention.output.dense', 'roberta.encoder.layer.2.intermediate.dense', 'roberta.encoder.layer.2.output.dense', 'roberta.encoder.layer.3.attention.self.query', 'roberta.encoder.layer.3.attention.self.key', 'roberta.encoder.layer.3.attention.output.dense', 'roberta.encoder.layer.3.intermediate.dense', 'roberta.encoder.layer.3.output.dense', 'roberta.encoder.layer.4.attention.self.query', 'roberta.encoder.layer.4.attention.self.key', 'roberta.encoder.layer.4.attention.output.dense', 'roberta.encoder.layer.4.intermediate.dense', 'roberta.encoder.layer.4.output.dense', 'roberta.encoder.layer.5.attention.self.query', 'roberta.encoder.layer.5.attention.self.key', 'roberta.encoder.layer.5.attention.output.dense', 'roberta.encoder.layer.5.intermediate.dense', 'roberta.encoder.layer.5.output.dense', 'classifier.dense']\n",
            "trainable params: 6099460 || all params: 73603588 || trainable%: 8.286905795951142\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.6601, Val Loss: 0.5572, Val MCC: 0.5160, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.4555, Val Loss: 0.3868, Val MCC: 0.6401, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.3569, Val Loss: 0.3390, Val MCC: 0.7019, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.2952, Val Loss: 0.2993, Val MCC: 0.7557, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.2500, Val Loss: 0.2597, Val MCC: 0.8003, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.2202, Val Loss: 0.2409, Val MCC: 0.8115, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.1758, Val Loss: 0.2274, Val MCC: 0.8329, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.1585, Val Loss: 0.1941, Val MCC: 0.8558, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.1401, Val Loss: 0.1864, Val MCC: 0.8612, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.1145, Val Loss: 0.1936, Val MCC: 0.8571, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1027, Val Loss: 0.1766, Val MCC: 0.8845, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.0904, Val Loss: 0.1806, Val MCC: 0.8749, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.0739, Val Loss: 0.1683, Val MCC: 0.8845, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.0681, Val Loss: 0.1834, Val MCC: 0.8720, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.0623, Val Loss: 0.1754, Val MCC: 0.8929, lr: 1.000e-05\n",
            "Epoch 15/29, Train Loss: 0.0557, Val Loss: 0.1530, Val MCC: 0.9034, lr: 1.000e-05\n",
            "Epoch 16/29, Train Loss: 0.0511, Val Loss: 0.1438, Val MCC: 0.9191, lr: 1.000e-05\n",
            "Epoch 17/29, Train Loss: 0.0491, Val Loss: 0.1574, Val MCC: 0.9191, lr: 1.000e-05\n",
            "Epoch 18/29, Train Loss: 0.0417, Val Loss: 0.1653, Val MCC: 0.9059, lr: 1.000e-05\n",
            "Epoch 19/29, Train Loss: 0.0442, Val Loss: 0.1506, Val MCC: 0.9102, lr: 1.000e-05\n",
            "Best epoch: 16, Best loss: 0.1438\n",
            "\n",
            "\n",
            "> Fold 3\n",
            "Using Lora\n",
            "Target modules : ['roberta.encoder.layer.0.attention.self.query', 'roberta.encoder.layer.0.attention.self.key', 'roberta.encoder.layer.0.attention.output.dense', 'roberta.encoder.layer.0.intermediate.dense', 'roberta.encoder.layer.0.output.dense', 'roberta.encoder.layer.1.attention.self.query', 'roberta.encoder.layer.1.attention.self.key', 'roberta.encoder.layer.1.attention.output.dense', 'roberta.encoder.layer.1.intermediate.dense', 'roberta.encoder.layer.1.output.dense', 'roberta.encoder.layer.2.attention.self.query', 'roberta.encoder.layer.2.attention.self.key', 'roberta.encoder.layer.2.attention.output.dense', 'roberta.encoder.layer.2.intermediate.dense', 'roberta.encoder.layer.2.output.dense', 'roberta.encoder.layer.3.attention.self.query', 'roberta.encoder.layer.3.attention.self.key', 'roberta.encoder.layer.3.attention.output.dense', 'roberta.encoder.layer.3.intermediate.dense', 'roberta.encoder.layer.3.output.dense', 'roberta.encoder.layer.4.attention.self.query', 'roberta.encoder.layer.4.attention.self.key', 'roberta.encoder.layer.4.attention.output.dense', 'roberta.encoder.layer.4.intermediate.dense', 'roberta.encoder.layer.4.output.dense', 'roberta.encoder.layer.5.attention.self.query', 'roberta.encoder.layer.5.attention.self.key', 'roberta.encoder.layer.5.attention.output.dense', 'roberta.encoder.layer.5.intermediate.dense', 'roberta.encoder.layer.5.output.dense', 'classifier.dense']\n",
            "trainable params: 6099460 || all params: 73603588 || trainable%: 8.286905795951142\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.6499, Val Loss: 0.5130, Val MCC: 0.5062, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.4435, Val Loss: 0.3594, Val MCC: 0.6757, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.3454, Val Loss: 0.3189, Val MCC: 0.7306, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.2905, Val Loss: 0.2847, Val MCC: 0.7438, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.2497, Val Loss: 0.2452, Val MCC: 0.7929, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.2095, Val Loss: 0.2336, Val MCC: 0.8022, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.1850, Val Loss: 0.2452, Val MCC: 0.7938, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.1646, Val Loss: 0.2191, Val MCC: 0.8154, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.1498, Val Loss: 0.2094, Val MCC: 0.8228, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.1351, Val Loss: 0.2041, Val MCC: 0.8191, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1164, Val Loss: 0.1841, Val MCC: 0.8313, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.1080, Val Loss: 0.1629, Val MCC: 0.8216, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.0997, Val Loss: 0.2126, Val MCC: 0.8172, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.0844, Val Loss: 0.1957, Val MCC: 0.8268, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.0772, Val Loss: 0.1496, Val MCC: 0.8545, lr: 1.000e-05\n",
            "Epoch 15/29, Train Loss: 0.0617, Val Loss: 0.2114, Val MCC: 0.8209, lr: 1.000e-05\n",
            "Epoch 16/29, Train Loss: 0.0681, Val Loss: 0.1536, Val MCC: 0.8624, lr: 1.000e-05\n",
            "Epoch 17/29, Train Loss: 0.0540, Val Loss: 0.1683, Val MCC: 0.8588, lr: 1.000e-05\n",
            "Best epoch: 14, Best loss: 0.1496\n",
            "\n",
            "\n",
            "> Fold 4\n",
            "Using Lora\n",
            "Target modules : ['roberta.encoder.layer.0.attention.self.query', 'roberta.encoder.layer.0.attention.self.key', 'roberta.encoder.layer.0.attention.output.dense', 'roberta.encoder.layer.0.intermediate.dense', 'roberta.encoder.layer.0.output.dense', 'roberta.encoder.layer.1.attention.self.query', 'roberta.encoder.layer.1.attention.self.key', 'roberta.encoder.layer.1.attention.output.dense', 'roberta.encoder.layer.1.intermediate.dense', 'roberta.encoder.layer.1.output.dense', 'roberta.encoder.layer.2.attention.self.query', 'roberta.encoder.layer.2.attention.self.key', 'roberta.encoder.layer.2.attention.output.dense', 'roberta.encoder.layer.2.intermediate.dense', 'roberta.encoder.layer.2.output.dense', 'roberta.encoder.layer.3.attention.self.query', 'roberta.encoder.layer.3.attention.self.key', 'roberta.encoder.layer.3.attention.output.dense', 'roberta.encoder.layer.3.intermediate.dense', 'roberta.encoder.layer.3.output.dense', 'roberta.encoder.layer.4.attention.self.query', 'roberta.encoder.layer.4.attention.self.key', 'roberta.encoder.layer.4.attention.output.dense', 'roberta.encoder.layer.4.intermediate.dense', 'roberta.encoder.layer.4.output.dense', 'roberta.encoder.layer.5.attention.self.query', 'roberta.encoder.layer.5.attention.self.key', 'roberta.encoder.layer.5.attention.output.dense', 'roberta.encoder.layer.5.intermediate.dense', 'roberta.encoder.layer.5.output.dense', 'classifier.dense']\n",
            "trainable params: 6099460 || all params: 73603588 || trainable%: 8.286905795951142\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.6631, Val Loss: 0.5524, Val MCC: 0.5945, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.4711, Val Loss: 0.3912, Val MCC: 0.6670, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.3605, Val Loss: 0.3396, Val MCC: 0.6947, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.2984, Val Loss: 0.3149, Val MCC: 0.7244, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.2588, Val Loss: 0.2736, Val MCC: 0.7705, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.2258, Val Loss: 0.2817, Val MCC: 0.7694, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.2017, Val Loss: 0.2700, Val MCC: 0.7705, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.1756, Val Loss: 0.2359, Val MCC: 0.8118, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.1481, Val Loss: 0.2342, Val MCC: 0.8135, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.1340, Val Loss: 0.2374, Val MCC: 0.8211, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1222, Val Loss: 0.2166, Val MCC: 0.8303, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.1043, Val Loss: 0.2058, Val MCC: 0.8397, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.0866, Val Loss: 0.2805, Val MCC: 0.8159, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.0832, Val Loss: 0.2360, Val MCC: 0.8266, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.0682, Val Loss: 0.2267, Val MCC: 0.8435, lr: 1.000e-05\n",
            "Best epoch: 11, Best loss: 0.2058\n",
            "\n",
            "\n",
            "> Fold 5\n",
            "Using Lora\n",
            "Target modules : ['roberta.encoder.layer.0.attention.self.query', 'roberta.encoder.layer.0.attention.self.key', 'roberta.encoder.layer.0.attention.output.dense', 'roberta.encoder.layer.0.intermediate.dense', 'roberta.encoder.layer.0.output.dense', 'roberta.encoder.layer.1.attention.self.query', 'roberta.encoder.layer.1.attention.self.key', 'roberta.encoder.layer.1.attention.output.dense', 'roberta.encoder.layer.1.intermediate.dense', 'roberta.encoder.layer.1.output.dense', 'roberta.encoder.layer.2.attention.self.query', 'roberta.encoder.layer.2.attention.self.key', 'roberta.encoder.layer.2.attention.output.dense', 'roberta.encoder.layer.2.intermediate.dense', 'roberta.encoder.layer.2.output.dense', 'roberta.encoder.layer.3.attention.self.query', 'roberta.encoder.layer.3.attention.self.key', 'roberta.encoder.layer.3.attention.output.dense', 'roberta.encoder.layer.3.intermediate.dense', 'roberta.encoder.layer.3.output.dense', 'roberta.encoder.layer.4.attention.self.query', 'roberta.encoder.layer.4.attention.self.key', 'roberta.encoder.layer.4.attention.output.dense', 'roberta.encoder.layer.4.intermediate.dense', 'roberta.encoder.layer.4.output.dense', 'roberta.encoder.layer.5.attention.self.query', 'roberta.encoder.layer.5.attention.self.key', 'roberta.encoder.layer.5.attention.output.dense', 'roberta.encoder.layer.5.intermediate.dense', 'roberta.encoder.layer.5.output.dense', 'classifier.dense']\n",
            "trainable params: 6099460 || all params: 73603588 || trainable%: 8.286905795951142\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 0.6551, Val Loss: 0.6030, Val MCC: 0.4957, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.4559, Val Loss: 0.4461, Val MCC: 0.6221, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.3578, Val Loss: 0.4205, Val MCC: 0.6434, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.3002, Val Loss: 0.3902, Val MCC: 0.6864, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.2467, Val Loss: 0.3799, Val MCC: 0.7080, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.2129, Val Loss: 0.3719, Val MCC: 0.7176, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.1914, Val Loss: 0.3168, Val MCC: 0.7389, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.1657, Val Loss: 0.3302, Val MCC: 0.7448, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.1438, Val Loss: 0.3528, Val MCC: 0.7482, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.1326, Val Loss: 0.3003, Val MCC: 0.7669, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1219, Val Loss: 0.2915, Val MCC: 0.7757, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.0987, Val Loss: 0.2801, Val MCC: 0.8021, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.0898, Val Loss: 0.2735, Val MCC: 0.7944, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.0788, Val Loss: 0.2855, Val MCC: 0.8138, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.0784, Val Loss: 0.3984, Val MCC: 0.7820, lr: 1.000e-05\n",
            "Epoch 15/29, Train Loss: 0.0655, Val Loss: 0.3540, Val MCC: 0.7794, lr: 1.000e-05\n",
            "Best epoch: 12, Best loss: 0.2735\n",
            "\n",
            "\n",
            ">> Folds metrics:\n",
            " - Best epoch: [7.0000 <-> 16.0000]\n",
            " - Accuracy: 0.9272 ± 0.0212\n",
            " - MCC: 0.8454 ± 0.0420\n",
            " - F1-micro: 0.9272 ± 0.0212\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9272\n",
            " - f1_macro: 0.9187\n",
            " - f1_micro: 0.9272\n",
            " - f1_weighted: 0.9287\n",
            " - mcc: 0.8441\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class                                       Precision      Recall          F1     Support\n",
            "Informations et services spécialisés           0.9853      0.9079      0.9450        1629\n",
            "Support client opérationnel                    0.8262      0.9701      0.8924         735\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "                                         Informations et services spécialisés      Support client opérationnel      \n",
            "Informations et services spécialisés                   1479                                  150                  \n",
            "Support client opérationnel                             22                                   713                  \n",
            "Elapsed time: 00:41:13\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "n_splits = 5\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Define a custom classification head\n",
        "head_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels},\n",
        "    ]\n",
        "\n",
        "# Create Classification Model from \"Camembert-base\"\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"cmarkea/distilcamembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=head_layer_configs\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                            labels_names=labels_names,\n",
        "                            optimizer_class=AdamW,\n",
        "                            use_lora=True,\n",
        "                            lora_r = 64,\n",
        "                            lora_alpha= 128,\n",
        "                            lora_dropout = 0.01,\n",
        "                            )\n",
        "\n",
        "# Cross validate with Earlystopping\n",
        "rets = trainer.cross_validation(texts=texts,\n",
        "              labels=labels,\n",
        "              n_splits=n_splits,\n",
        "              num_epochs=num_epochs,\n",
        "              batch_size=batch_size,\n",
        "              patience=patience,\n",
        "              min_delta=min_delta,\n",
        "              balanced=True)\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyqAwuAd00HN",
        "outputId": "70dca1de-6811-42f3-fb36-c03902cbc5a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV Folds max epoch: 16\n"
          ]
        }
      ],
      "source": [
        "epochs_list = [k.get(\"best_epoch\") for k in rets.get(\"cv_folds\")]\n",
        "max_epoch = int(np.max(epochs_list))\n",
        "print(\"CV Folds max epoch:\", max_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YrCUgdZYZCE"
      },
      "source": [
        "## Full Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oz6n1tqYZCE",
        "outputId": "1350912e-9401-4967-ed9c-8737083de585"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Using Lora\n",
            "Target modules : ['base_model.encoder.layer.0.attention.self.query', 'base_model.encoder.layer.0.attention.self.key', 'base_model.encoder.layer.0.attention.output.dense', 'base_model.encoder.layer.0.intermediate.dense', 'base_model.encoder.layer.0.output.dense', 'base_model.encoder.layer.1.attention.self.query', 'base_model.encoder.layer.1.attention.self.key', 'base_model.encoder.layer.1.attention.output.dense', 'base_model.encoder.layer.1.intermediate.dense', 'base_model.encoder.layer.1.output.dense', 'base_model.encoder.layer.2.attention.self.query', 'base_model.encoder.layer.2.attention.self.key', 'base_model.encoder.layer.2.attention.output.dense', 'base_model.encoder.layer.2.intermediate.dense', 'base_model.encoder.layer.2.output.dense', 'base_model.encoder.layer.3.attention.self.query', 'base_model.encoder.layer.3.attention.self.key', 'base_model.encoder.layer.3.attention.output.dense', 'base_model.encoder.layer.3.intermediate.dense', 'base_model.encoder.layer.3.output.dense', 'base_model.encoder.layer.4.attention.self.query', 'base_model.encoder.layer.4.attention.self.key', 'base_model.encoder.layer.4.attention.output.dense', 'base_model.encoder.layer.4.intermediate.dense', 'base_model.encoder.layer.4.output.dense', 'base_model.encoder.layer.5.attention.self.query', 'base_model.encoder.layer.5.attention.self.key', 'base_model.encoder.layer.5.attention.output.dense', 'base_model.encoder.layer.5.intermediate.dense', 'base_model.encoder.layer.5.output.dense', 'base_model.pooler.dense']\n",
            "trainable params: 5871108 || all params: 73965828 || trainable%: 7.937595182467233\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/15, Training Loss: 0.5785\n",
            "Epoch 1/15, Training Loss: 0.4428\n",
            "Epoch 2/15, Training Loss: 0.3628\n",
            "Epoch 3/15, Training Loss: 0.2992\n",
            "Epoch 4/15, Training Loss: 0.2560\n",
            "Epoch 5/15, Training Loss: 0.2172\n",
            "Epoch 6/15, Training Loss: 0.1843\n",
            "Epoch 7/15, Training Loss: 0.1615\n",
            "Epoch 8/15, Training Loss: 0.1374\n",
            "Epoch 9/15, Training Loss: 0.1228\n",
            "Epoch 10/15, Training Loss: 0.1065\n",
            "Epoch 11/15, Training Loss: 0.0935\n",
            "Epoch 12/15, Training Loss: 0.0807\n",
            "Epoch 13/15, Training Loss: 0.0758\n",
            "Epoch 14/15, Training Loss: 0.0647\n",
            "Epoch 15/15, Training Loss: 0.0607\n",
            "Elapsed time: 00:08:37\n"
          ]
        }
      ],
      "source": [
        "num_epochs = max_epoch\n",
        "batch_size = 8\n",
        "train_size = 1.0\n",
        "\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Define a custom classification head\n",
        "head_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels},\n",
        "    ]\n",
        "\n",
        "# Create Classification Model\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"cmarkea/distilcamembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=head_layer_configs\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                            labels_names=labels_names,\n",
        "                            optimizer_class=AdamW,\n",
        "                            use_lora=True,\n",
        "                            lora_r = 64,\n",
        "                            lora_alpha= 128,\n",
        "                            lora_dropout = 0.01,\n",
        "                            )\n",
        "\n",
        "# Train the model\n",
        "ret = trainer.train(texts=texts,\n",
        "                    labels=labels,\n",
        "                    train_size=train_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Save model and adaptater\n",
        "trainer.save_model(\"./model-binary_v1\")\n",
        "trainer.save_adaptater(\"./adaptater-binary_v1\")\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cg03kDuYZCF"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsRAMj0gYZCF"
      },
      "source": [
        "### Reload model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffZlwIseYZCF"
      },
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "bee_mlm_model = BeeMLMClassifier.load_model_safetensors(\"./model-binary_v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM6WIzu9YZCF"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KvoRux3YZCF",
        "outputId": "9d20f82b-34c5-41b8-e930-bf77e82febff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8405947518771781\n"
          ]
        }
      ],
      "source": [
        "y_preds = bee_mlm_model.predict(test_texts, batch_size=50, device=\"cpu\")\n",
        "mcc = matthews_corrcoef(test_labels, y_preds)\n",
        "print(mcc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppQCNA_4hOY_"
      },
      "source": [
        "# End of game"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ee8a8df6d204056a5f2c617cb320efb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10477fe81ecf413eab4533197e8e8b53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "16130cde324543b2879a185200213902": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69a75368ae69463da88e63700b301d44",
            "placeholder": "​",
            "style": "IPY_MODEL_8b8cb0263e1342f4bafbbd80a0873142",
            "value": "Generating test split: "
          }
        },
        "16d0472af01148ffbe2660f65c2cc2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9412f473d59142bc8adea6bb9b9387e2",
            "placeholder": "​",
            "style": "IPY_MODEL_fa0c5d009ab44f9f886724a0023d8271",
            "value": "Generating themes split: "
          }
        },
        "21a1f27fac834c01b6d23347f7452375": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a072f14a6a14446a2a67c6bb4c2ef28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee8a8df6d204056a5f2c617cb320efb",
            "placeholder": "​",
            "style": "IPY_MODEL_21a1f27fac834c01b6d23347f7452375",
            "value": "Generating train split: "
          }
        },
        "2a07fd2aafb94f289b8d8fed15debd99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3037a2227def41f6a7e9e567225249bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0f7505674654f839165572649944883",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f497597b5a344dcb9f9cd76817e7a6c",
            "value": 1
          }
        },
        "4542439f976244d48ce7dd3e927baa47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10477fe81ecf413eab4533197e8e8b53",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9776da59b4df447e9bf955c1d8a40972",
            "value": 1
          }
        },
        "4840621a4bcd46fc99f6b98d51df3ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76bbf3d0e2ff435b97b7f91dc7a9857a",
            "placeholder": "​",
            "style": "IPY_MODEL_8a84105e62b04ab9b89bc62e2ebcf86c",
            "value": " 2364/0 [00:00&lt;00:00, 40132.66 examples/s]"
          }
        },
        "4f497597b5a344dcb9f9cd76817e7a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "573ea5e66b404d788ce0b877ee98a5f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a0320a475a244779bf9e2e40aa44405": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e8d4a4719840ba971add9bd5dd9fee",
            "placeholder": "​",
            "style": "IPY_MODEL_fe3eadd4a3424596a00fdd4cc8324baa",
            "value": " 591/0 [00:00&lt;00:00, 21693.16 examples/s]"
          }
        },
        "5a870e0b3280444d89b026d1feb708d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7995745374d42dbb1d7a78dab8428b5",
            "placeholder": "​",
            "style": "IPY_MODEL_b813b77b9f6e4696829bad390a7641dd",
            "value": " 100/0 [00:00&lt;00:00, 5167.31 examples/s]"
          }
        },
        "60e8d4a4719840ba971add9bd5dd9fee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a75368ae69463da88e63700b301d44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76bbf3d0e2ff435b97b7f91dc7a9857a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86995c1bfb1c4d4daf9fe51f61f923ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a84105e62b04ab9b89bc62e2ebcf86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b8cb0263e1342f4bafbbd80a0873142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9412f473d59142bc8adea6bb9b9387e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9776da59b4df447e9bf955c1d8a40972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0f7505674654f839165572649944883": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a9f70c65e83e4dc4b6601161541c9bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a07fd2aafb94f289b8d8fed15debd99",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c90ae4958bd24f35b0ce9db6fd3cc7d9",
            "value": 1
          }
        },
        "b813b77b9f6e4696829bad390a7641dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1c2bd1ccb1b428586f7235f6aa6f2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16d0472af01148ffbe2660f65c2cc2ee",
              "IPY_MODEL_4542439f976244d48ce7dd3e927baa47",
              "IPY_MODEL_5a870e0b3280444d89b026d1feb708d9"
            ],
            "layout": "IPY_MODEL_573ea5e66b404d788ce0b877ee98a5f4"
          }
        },
        "c7995745374d42dbb1d7a78dab8428b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90ae4958bd24f35b0ce9db6fd3cc7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8f358fb22a943f78e69ce1a1aeb7c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7147ceb27748189b02f9c84b405bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16130cde324543b2879a185200213902",
              "IPY_MODEL_a9f70c65e83e4dc4b6601161541c9bbb",
              "IPY_MODEL_5a0320a475a244779bf9e2e40aa44405"
            ],
            "layout": "IPY_MODEL_e8f358fb22a943f78e69ce1a1aeb7c1b"
          }
        },
        "fa0c5d009ab44f9f886724a0023d8271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe3eadd4a3424596a00fdd4cc8324baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe4962fa766c4bee98e3058968d59091": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a072f14a6a14446a2a67c6bb4c2ef28",
              "IPY_MODEL_3037a2227def41f6a7e9e567225249bf",
              "IPY_MODEL_4840621a4bcd46fc99f6b98d51df3ad5"
            ],
            "layout": "IPY_MODEL_86995c1bfb1c4d4daf9fe51f61f923ed"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
