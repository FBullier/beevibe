{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDY7mUu58FMN"
      },
      "source": [
        "# Beevibe - Multiclass tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK7ydTAYYZB-"
      },
      "source": [
        "## Manage Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ApCvyV9YeHD"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY9BHVb9YhcF",
        "outputId": "240c0589-4028-4f3c-fe02-9f80c1f59622"
      },
      "outputs": [],
      "source": [
        "# Install Beevibe\n",
        "! pip install beevibe --quiet --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzkYGZkLYxTj"
      },
      "outputs": [],
      "source": [
        "# Install Watermark\n",
        "! pip install watermark --quiet --progress-bar off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXry0w1PHBCK"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Xcs71pBHRzk"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import numpy as np\n",
        "from watermark import watermark\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from beevibe import BeeTrainer, BeeMLMClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQz8AcJaG7pJ"
      },
      "source": [
        "## GPU Card"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5ytYfftGWuJ",
        "outputId": "6e14d632-1555-4b53-a2a3-3757ca1c3ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Feb  6 16:19:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRejiKEqvn7t"
      },
      "source": [
        "## Drive Directory\n",
        "\n",
        "<!> Please adjust to your notebook path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX6wUJrOeJnS"
      },
      "outputs": [],
      "source": [
        "# Path sur le projet\n",
        "sys.path.insert(0, \"..\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjQyB_F7CyPT"
      },
      "source": [
        "## Packages versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jARbtmvuCR50",
        "outputId": "a20d15f2-4ea8-48cf-a4f5-32afe6e7cb16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last updated: 2025-02-06T16:19:41.750498+00:00\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.11.11\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 6.1.85+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 8\n",
            "Architecture: 64bit\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(watermark())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maanWhDACXBD",
        "outputId": "a46702c3-c962-4c2b-a703-1b6590ee4056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pandas       : 2.2.2\n",
            "numpy        : 1.26.4\n",
            "scipy        : 1.13.1\n",
            "sklearn      : 1.6.1\n",
            "torch        : 2.5.1+cu124\n",
            "transformers : 4.47.1\n",
            "tokenizers   : 0.21.0\n",
            "sentencepiece: 0.2.0\n",
            "datasets     : 3.2.0\n",
            "beevibe      : 0.1.0.dev13\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(watermark(packages=\"pandas,numpy,scipy,sklearn,torch,transformers,tokenizers,sentencepiece,datasets,beevibe\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSR2ozK1vkz8"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KGoHUaCYZCB"
      },
      "source": [
        "### Get Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqlBsFEqpHfl",
        "outputId": "0de469f8-00f1-4b15-8929-256d8f3ef321"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"train\": \"elegana_train_v0_1.csv\",\n",
        "    \"test\": \"elegana_test_v0_1.csv\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"Franbul/elegana_relation_client_FR\",\n",
        "    data_files=data_files,\n",
        "    sep=\"|\")\n",
        "\n",
        "pd_train = dataset[\"train\"].to_pandas()\n",
        "pd_test = dataset[\"test\"].to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJbC5wKnYZCB"
      },
      "source": [
        "### Get Themes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBfEZNSDYZCB"
      },
      "outputs": [],
      "source": [
        "data_files = {\n",
        "    \"themes\": \"elegana_themes_v0_1.csv\"\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"Franbul/elegana_relation_client_FR\",\n",
        "    data_files=data_files,\n",
        "    sep=\"|\")\n",
        "\n",
        "pd_themes = dataset[\"themes\"].to_pandas()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_9Fvvo5YZCB"
      },
      "source": [
        "### Merge datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_c9HmYHYZCB"
      },
      "outputs": [],
      "source": [
        "# Merge train, test and thems\n",
        "pd_data = pd.merge(pd_train, pd_themes, on=\"THEME\", how='left')\n",
        "pd_data_test = pd.merge(pd_test, pd_themes, on=\"THEME\", how='left')\n",
        "\n",
        "# Get a sample here\n",
        "#pd_data = pd_data.sample(200, random_state=1811)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CljMG0RYZCB",
        "outputId": "32254f00-1dd8-473d-c553-6403a2c9b85c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2364, 10)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "jbajMkFcPQoh",
        "outputId": "43efcc99-1a22-421c-da24-dfd348fee270"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd_data\",\n  \"rows\": 2364,\n  \"fields\": [\n    {\n      \"column\": \"CLIENT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2124,\n        \"samples\": [\n          \"J'ai accidentellement command\\u00e9 deux fois le m\\u00eame chapeau. Pouvez-vous m'aider \\u00e0 annuler l'une des commandes ?\",\n          \"Organisez-vous des \\u00e9v\\u00e9nements pour promouvoir l'art et la culture ?\",\n          \"Les anses de mon sac se sont d\\u00e9tach\\u00e9es apr\\u00e8s une utilisation mod\\u00e9r\\u00e9e, ce n'est pas normal.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CONSEILLER\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2074,\n        \"samples\": [\n          \"Nous avons toujours des projets passionnants en cours avec de nouveaux artistes et designers. Pour \\u00eatre parmi les premiers \\u00e0 conna\\u00eetre nos futures collaborations, nous vous invitons \\u00e0 vous inscrire \\u00e0 notre newsletter ou \\u00e0 nous suivre sur les r\\u00e9seaux sociaux.\",\n          \"Je suis vraiment d\\u00e9sol\\u00e9 pour ce retard. Je vais v\\u00e9rifier imm\\u00e9diatement ce qui a pu se passer avec votre commande.\",\n          \"Bien s\\u00fbr, je suis l\\u00e0 pour vous aider. Pouvez-vous me dire quelles difficult\\u00e9s vous rencontrez? En g\\u00e9n\\u00e9ral, vous devez simplement entrer votre adresse email dans le champ pr\\u00e9vu \\u00e0 cet effet sur notre site et confirmer votre inscription en cliquant sur le lien que vous recevrez par email.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THEME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Questions sur la politique de retour\",\n          \"Probl\\u00e8mes de livraison internationale\",\n          \"Informations sur les limitations d'exp\\u00e9dition\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DESCRIPTION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Clarifications sur les conditions de retour.\",\n          \"Questions ou probl\\u00e8mes concernant la livraison hors du pays.\",\n          \"Restrictions ou limitations pour l'exp\\u00e9dition dans certaines r\\u00e9gions ou pays.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_CLASSES\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Support client op\\u00e9rationnel\",\n          \"Informations et services sp\\u00e9cialis\\u00e9s\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5_CLASSES\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Services exclusifs, programmes et personnalisations\",\n          \"Assistance technique et support imm\\u00e9diat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 63,\n        \"samples\": [\n          \"Combinaison\",\n          \"Facturation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"Remboursement\",\n          \"Caract\\u00e9ristique\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 81,\n        \"samples\": [\n          \"Assistance\",\n          \"Sp\\u00e9cifique\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"Produit\",\n          \"Demande\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "pd_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-15774254-6cbd-4f5d-96a9-28b00e582f9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLIENT</th>\n",
              "      <th>CONSEILLER</th>\n",
              "      <th>THEME</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>2_CLASSES</th>\n",
              "      <th>5_CLASSES</th>\n",
              "      <th>LABEL_1</th>\n",
              "      <th>LABEL_2</th>\n",
              "      <th>LABEL_3</th>\n",
              "      <th>LABEL_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Quelle est la taille de ce chapeau ?</td>\n",
              "      <td>La taille de ce chapeau est de 58 cm de circon...</td>\n",
              "      <td>Demande d'informations produit</td>\n",
              "      <td>Questions spécifiques sur les caractéristiques...</td>\n",
              "      <td>Informations et services spécialisés</td>\n",
              "      <td>Conseils et informations produits</td>\n",
              "      <td>Produit</td>\n",
              "      <td>Caractéristique</td>\n",
              "      <td>Spécifique</td>\n",
              "      <td>Demande</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Quels sont vos délais de livraison pour les co...</td>\n",
              "      <td>Nos délais de livraison pour les commandes en ...</td>\n",
              "      <td>Demande d'informations sur les achats en gros</td>\n",
              "      <td>Conditions et possibilités pour les achats en ...</td>\n",
              "      <td>Informations et services spécialisés</td>\n",
              "      <td>Services exclusifs, programmes et personnalisa...</td>\n",
              "      <td>Gros</td>\n",
              "      <td>Condition</td>\n",
              "      <td>Professionnel</td>\n",
              "      <td>Possibilité</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nous avons besoin de tenues pour un événement ...</td>\n",
              "      <td>Oui, en fonction du thème de l'événement, nous...</td>\n",
              "      <td>Demande de conseils pour les achats de groupe</td>\n",
              "      <td>Conseils pour effectuer des achats groupés (po...</td>\n",
              "      <td>Informations et services spécialisés</td>\n",
              "      <td>Conseils et informations produits</td>\n",
              "      <td>Achat</td>\n",
              "      <td>Groupe</td>\n",
              "      <td>Événement</td>\n",
              "      <td>Mariage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Le gilet que j'ai commandé est trop petit. Pui...</td>\n",
              "      <td>Je suis désolé d'apprendre que la taille du gi...</td>\n",
              "      <td>Échange de produit</td>\n",
              "      <td>Demande d'échange pour un autre taille, couleu...</td>\n",
              "      <td>Support client opérationnel</td>\n",
              "      <td>Commandes, livraison et suivi</td>\n",
              "      <td>Produit</td>\n",
              "      <td>Taille</td>\n",
              "      <td>Couleur</td>\n",
              "      <td>Option</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Est-ce que vous proposez des remises pour les ...</td>\n",
              "      <td>Oui, nous offrons des remises aux professionne...</td>\n",
              "      <td>Demande d'informations sur les achats en gros</td>\n",
              "      <td>Conditions et possibilités pour les achats en ...</td>\n",
              "      <td>Informations et services spécialisés</td>\n",
              "      <td>Services exclusifs, programmes et personnalisa...</td>\n",
              "      <td>Gros</td>\n",
              "      <td>Condition</td>\n",
              "      <td>Professionnel</td>\n",
              "      <td>Possibilité</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15774254-6cbd-4f5d-96a9-28b00e582f9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15774254-6cbd-4f5d-96a9-28b00e582f9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15774254-6cbd-4f5d-96a9-28b00e582f9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bddac204-ae7f-4d21-bb2e-33d42e7321cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bddac204-ae7f-4d21-bb2e-33d42e7321cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bddac204-ae7f-4d21-bb2e-33d42e7321cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              CLIENT  \\\n",
              "0               Quelle est la taille de ce chapeau ?   \n",
              "1  Quels sont vos délais de livraison pour les co...   \n",
              "2  Nous avons besoin de tenues pour un événement ...   \n",
              "3  Le gilet que j'ai commandé est trop petit. Pui...   \n",
              "4  Est-ce que vous proposez des remises pour les ...   \n",
              "\n",
              "                                          CONSEILLER  \\\n",
              "0  La taille de ce chapeau est de 58 cm de circon...   \n",
              "1  Nos délais de livraison pour les commandes en ...   \n",
              "2  Oui, en fonction du thème de l'événement, nous...   \n",
              "3  Je suis désolé d'apprendre que la taille du gi...   \n",
              "4  Oui, nous offrons des remises aux professionne...   \n",
              "\n",
              "                                           THEME  \\\n",
              "0                 Demande d'informations produit   \n",
              "1  Demande d'informations sur les achats en gros   \n",
              "2  Demande de conseils pour les achats de groupe   \n",
              "3                             Échange de produit   \n",
              "4  Demande d'informations sur les achats en gros   \n",
              "\n",
              "                                         DESCRIPTION  \\\n",
              "0  Questions spécifiques sur les caractéristiques...   \n",
              "1  Conditions et possibilités pour les achats en ...   \n",
              "2  Conseils pour effectuer des achats groupés (po...   \n",
              "3  Demande d'échange pour un autre taille, couleu...   \n",
              "4  Conditions et possibilités pour les achats en ...   \n",
              "\n",
              "                              2_CLASSES  \\\n",
              "0  Informations et services spécialisés   \n",
              "1  Informations et services spécialisés   \n",
              "2  Informations et services spécialisés   \n",
              "3           Support client opérationnel   \n",
              "4  Informations et services spécialisés   \n",
              "\n",
              "                                           5_CLASSES  LABEL_1  \\\n",
              "0                  Conseils et informations produits  Produit   \n",
              "1  Services exclusifs, programmes et personnalisa...     Gros   \n",
              "2                  Conseils et informations produits    Achat   \n",
              "3                      Commandes, livraison et suivi  Produit   \n",
              "4  Services exclusifs, programmes et personnalisa...     Gros   \n",
              "\n",
              "           LABEL_2        LABEL_3      LABEL_4  \n",
              "0  Caractéristique     Spécifique      Demande  \n",
              "1        Condition  Professionnel  Possibilité  \n",
              "2           Groupe      Événement      Mariage  \n",
              "3           Taille        Couleur       Option  \n",
              "4        Condition  Professionnel  Possibilité  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XdFrFVLP9yj"
      },
      "source": [
        "### Get texts & labels for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "wI4fA2_pYZCC",
        "outputId": "5290fcfe-be72-4128-e734-25066d24456e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_CLASSES</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Services exclusifs, programmes et personnalisations</th>\n",
              "      <td>1126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Engagements, événements et initiatives</th>\n",
              "      <td>413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Commandes, livraison et suivi</th>\n",
              "      <td>370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conseils et informations produits</th>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Assistance technique et support immédiat</th>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "5_CLASSES\n",
              "Services exclusifs, programmes et personnalisations    1126\n",
              "Engagements, événements et initiatives                  413\n",
              "Commandes, livraison et suivi                           370\n",
              "Conseils et informations produits                       300\n",
              "Assistance technique et support immédiat                155\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd_data['5_CLASSES'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofsZ9bfKEo49",
        "outputId": "82f6b01a-b998-4008-9455-54c1d33d44cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train : Nb texts:2364, Nb labels:2364, Nb classes:5\n",
            "Test  : Nb texts:591, Nb labels:591, Nb classes:5\n"
          ]
        }
      ],
      "source": [
        "# Use THEME in 5-Classes for classification\n",
        "classes = np.unique(pd_data['5_CLASSES'])\n",
        "le_esg = LabelEncoder()\n",
        "le_esg.fit(classes)\n",
        "\n",
        "# Get sentences and labels to train\n",
        "labels_names = classes[le_esg.transform(classes)]\n",
        "labels = le_esg.transform(pd_data['5_CLASSES']).tolist()\n",
        "classes = np.unique(labels)\n",
        "texts = pd_data[\"CLIENT\"].values.tolist()\n",
        "print(f\"Train : Nb texts:{len(texts)}, Nb labels:{len(labels)}, Nb classes:{len(classes)}\")\n",
        "\n",
        "# Get sentences and labels to predict\n",
        "test_texts = pd_data_test[\"CLIENT\"].values.tolist()\n",
        "test_labels = le_esg.transform(pd_data_test['5_CLASSES']).tolist()\n",
        "print(f\"Test  : Nb texts:{len(test_texts)}, Nb labels:{len(test_labels)}, Nb classes:{len(np.unique(test_labels))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upF8CP1gYZCC"
      },
      "source": [
        "## Holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1eVuO2pdK6q",
        "outputId": "53cb4b5c-bc22-4e8d-f8fc-3737dec31983"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Using Lora\n",
            "Target modules : ['base_model.encoder.layer.0.attention.self.query', 'base_model.encoder.layer.0.attention.self.key', 'base_model.encoder.layer.0.attention.output.dense', 'base_model.encoder.layer.0.intermediate.dense', 'base_model.encoder.layer.0.output.dense', 'base_model.encoder.layer.1.attention.self.query', 'base_model.encoder.layer.1.attention.self.key', 'base_model.encoder.layer.1.attention.output.dense', 'base_model.encoder.layer.1.intermediate.dense', 'base_model.encoder.layer.1.output.dense', 'base_model.encoder.layer.2.attention.self.query', 'base_model.encoder.layer.2.attention.self.key', 'base_model.encoder.layer.2.attention.output.dense', 'base_model.encoder.layer.2.intermediate.dense', 'base_model.encoder.layer.2.output.dense', 'base_model.encoder.layer.3.attention.self.query', 'base_model.encoder.layer.3.attention.self.key', 'base_model.encoder.layer.3.attention.output.dense', 'base_model.encoder.layer.3.intermediate.dense', 'base_model.encoder.layer.3.output.dense', 'base_model.encoder.layer.4.attention.self.query', 'base_model.encoder.layer.4.attention.self.key', 'base_model.encoder.layer.4.attention.output.dense', 'base_model.encoder.layer.4.intermediate.dense', 'base_model.encoder.layer.4.output.dense', 'base_model.encoder.layer.5.attention.self.query', 'base_model.encoder.layer.5.attention.self.key', 'base_model.encoder.layer.5.attention.output.dense', 'base_model.encoder.layer.5.intermediate.dense', 'base_model.encoder.layer.5.output.dense', 'base_model.pooler.dense']\n",
            "trainable params: 4824586 || all params: 72919306 || trainable%: 6.616335597050251\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/19, Train Loss: 1.5999, Val Loss: 1.5190, Val MCC: 0.1884, lr: 1.000e-05\n",
            "Epoch 1/19, Train Loss: 1.4206, Val Loss: 1.2340, Val MCC: 0.4761, lr: 1.000e-05\n",
            "Epoch 2/19, Train Loss: 0.9560, Val Loss: 0.9290, Val MCC: 0.5312, lr: 1.000e-05\n",
            "Epoch 3/19, Train Loss: 0.6887, Val Loss: 0.7803, Val MCC: 0.6079, lr: 1.000e-05\n",
            "Epoch 4/19, Train Loss: 0.5453, Val Loss: 0.6734, Val MCC: 0.6462, lr: 1.000e-05\n",
            "Epoch 5/19, Train Loss: 0.4611, Val Loss: 0.6010, Val MCC: 0.6838, lr: 1.000e-05\n",
            "Epoch 6/19, Train Loss: 0.3984, Val Loss: 0.5473, Val MCC: 0.7165, lr: 1.000e-05\n",
            "Epoch 7/19, Train Loss: 0.3568, Val Loss: 0.5087, Val MCC: 0.7355, lr: 1.000e-05\n",
            "Epoch 8/19, Train Loss: 0.3161, Val Loss: 0.4663, Val MCC: 0.7483, lr: 1.000e-05\n",
            "Epoch 9/19, Train Loss: 0.2807, Val Loss: 0.4604, Val MCC: 0.7648, lr: 1.000e-05\n",
            "Epoch 10/19, Train Loss: 0.2556, Val Loss: 0.4377, Val MCC: 0.7760, lr: 1.000e-05\n",
            "Epoch 11/19, Train Loss: 0.2258, Val Loss: 0.4543, Val MCC: 0.7726, lr: 1.000e-05\n",
            "Epoch 12/19, Train Loss: 0.2100, Val Loss: 0.4118, Val MCC: 0.7961, lr: 1.000e-05\n",
            "Epoch 13/19, Train Loss: 0.1937, Val Loss: 0.3952, Val MCC: 0.7994, lr: 1.000e-05\n",
            "Epoch 14/19, Train Loss: 0.1769, Val Loss: 0.4059, Val MCC: 0.7990, lr: 1.000e-05\n",
            "Epoch 15/19, Train Loss: 0.1604, Val Loss: 0.3813, Val MCC: 0.8078, lr: 1.000e-05\n",
            "Epoch 16/19, Train Loss: 0.1468, Val Loss: 0.3131, Val MCC: 0.8405, lr: 1.000e-05\n",
            "Epoch 17/19, Train Loss: 0.1372, Val Loss: 0.3359, Val MCC: 0.8365, lr: 1.000e-05\n",
            "Epoch 18/19, Train Loss: 0.1299, Val Loss: 0.3627, Val MCC: 0.8244, lr: 1.000e-05\n",
            "Epoch 19/19, Train Loss: 0.1185, Val Loss: 0.3554, Val MCC: 0.8235, lr: 1.000e-05\n",
            "Best epoch: 16, Best loss: 0.3131\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.8859\n",
            " - f1_macro: 0.8746\n",
            " - f1_micro: 0.8859\n",
            " - f1_weighted: 0.8870\n",
            " - mcc: 0.8405\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class                                                      Precision      Recall          F1     Support\n",
            "Assistance technique et support immédiat                      0.7255      0.9250      0.8132          40\n",
            "Commandes, livraison et suivi                                 0.7955      0.9211      0.8537         114\n",
            "Conseils et informations produits                             0.8537      0.8974      0.8750          78\n",
            "Engagements, événements et initiatives                        0.9556      0.9348      0.9451         138\n",
            "Services exclusifs, programmes et personnalisations           0.9290      0.8471      0.8862         340\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "                                                             Assistance technique et support immédiat                   Commandes, livraison et suivi                      Conseils et informations produits                 Engagements, événements et initiatives         Services exclusifs, programmes et personnalisations \n",
            "Assistance technique et support immédiat                                      37                                                    0                                                    0                                                    0                                                    3                          \n",
            "Commandes, livraison et suivi                                                  0                                                   105                                                   1                                                    0                                                    8                          \n",
            "Conseils et informations produits                                              0                                                    0                                                   70                                                    0                                                    8                          \n",
            "Engagements, événements et initiatives                                         1                                                    0                                                    5                                                   129                                                   3                          \n",
            "Services exclusifs, programmes et personnalisations                           13                                                   27                                                    6                                                    6                                                   288                         \n",
            "Elapsed time: 00:08:29\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Create custom model : Normalized Layers\n",
        "custom_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": num_labels, \"activation\": None},\n",
        "    ]\n",
        "\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"cmarkea/distilcamembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=custom_layer_configs\n",
        ")\n",
        "\n",
        "trainer = BeeTrainer(model=model,\n",
        "                            labels_names=labels_names,\n",
        "                            optimizer_class=AdamW,\n",
        "                            use_lora=True,\n",
        "                            lora_r = 64,\n",
        "                            lora_alpha= 128,\n",
        "                            lora_dropout = 0.01,\n",
        "                            )\n",
        "\n",
        "ret = trainer.holdout(texts=texts,\n",
        "              labels=labels,\n",
        "              val_size=val_size,\n",
        "              num_epochs=num_epochs,\n",
        "              batch_size=batch_size,\n",
        "              patience=patience,\n",
        "              min_delta=min_delta,\n",
        "              balanced=True\n",
        "              )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC6RveVYYZCC"
      },
      "source": [
        "### Starter code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q07SV0BYZCC",
        "outputId": "80b96916-10c4-4636-c90b-fa2e844cb354"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Use optimizer : Adam\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 1.3343, Val Loss: 1.0701, Val MCC: 0.5585, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.7855, Val Loss: 0.7265, Val MCC: 0.7286, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.5525, Val Loss: 0.5388, Val MCC: 0.8015, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.4241, Val Loss: 0.4429, Val MCC: 0.8559, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.3519, Val Loss: 0.4439, Val MCC: 0.8669, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.3068, Val Loss: 0.3898, Val MCC: 0.8633, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.2496, Val Loss: 0.3820, Val MCC: 0.8634, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.2250, Val Loss: 0.3387, Val MCC: 0.8801, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.1892, Val Loss: 0.3322, Val MCC: 0.8763, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.1657, Val Loss: 0.3570, Val MCC: 0.8757, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1544, Val Loss: 0.3085, Val MCC: 0.8926, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.1374, Val Loss: 0.3535, Val MCC: 0.8745, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.1101, Val Loss: 0.3269, Val MCC: 0.8926, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.1010, Val Loss: 0.3126, Val MCC: 0.8869, lr: 1.000e-05\n",
            "Best epoch: 10, Best loss: 0.3085\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9254\n",
            " - f1_macro: 0.9273\n",
            " - f1_micro: 0.9254\n",
            " - f1_weighted: 0.9258\n",
            " - mcc: 0.8926\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class          Precision      Recall          F1     Support\n",
            "Class 0           0.9512      0.9750      0.9630          40\n",
            "Class 1           0.8281      0.9298      0.8760         114\n",
            "Class 2           0.9706      0.8462      0.9041          78\n",
            "Class 3           0.9778      0.9565      0.9670         138\n",
            "Class 4           0.9290      0.9235      0.9263         340\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "            Class 0  Class 1  Class 2  Class 3  Class 4 \n",
            "Class 0     39        0        0        0        1    \n",
            "Class 1      0       106       0        0        8    \n",
            "Class 2      0        1       66        1       10    \n",
            "Class 3      0        0        1       132       5    \n",
            "Class 4      2       21        1        2       314   \n",
            "Elapsed time: 00:12:23\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Create Classification Model from \"Camembert-base\"\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"camembert-base\",\n",
        "    num_labels = num_labels,\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                    )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HohRl1gJYZCD"
      },
      "source": [
        "### Modify classification  head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsm1_UnYZCD",
        "outputId": "ab7f48ab-92d7-4ca8-bdc0-163bb5c174c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Use optimizer : Adam\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 1.3351, Val Loss: 1.1422, Val MCC: 0.4502, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.8332, Val Loss: 0.8430, Val MCC: 0.6287, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.5602, Val Loss: 0.5850, Val MCC: 0.7402, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.3758, Val Loss: 0.3997, Val MCC: 0.8080, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.2665, Val Loss: 0.3226, Val MCC: 0.8547, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.1953, Val Loss: 0.2997, Val MCC: 0.8510, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.1546, Val Loss: 0.2894, Val MCC: 0.8617, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.1105, Val Loss: 0.2820, Val MCC: 0.8770, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.0943, Val Loss: 0.2702, Val MCC: 0.8855, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.0759, Val Loss: 0.3019, Val MCC: 0.8802, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.0854, Val Loss: 0.2804, Val MCC: 0.8958, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.0681, Val Loss: 0.2482, Val MCC: 0.9003, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.0626, Val Loss: 0.2773, Val MCC: 0.8978, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.0434, Val Loss: 0.3408, Val MCC: 0.8867, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.0403, Val Loss: 0.3484, Val MCC: 0.8812, lr: 1.000e-05\n",
            "Best epoch: 11, Best loss: 0.2482\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9310\n",
            " - f1_macro: 0.9288\n",
            " - f1_micro: 0.9310\n",
            " - f1_weighted: 0.9313\n",
            " - mcc: 0.9003\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class                                                      Precision      Recall          F1     Support\n",
            "Assistance technique et support immédiat                      0.9737      0.9250      0.9487          40\n",
            "Commandes, livraison et suivi                                 0.8667      0.9123      0.8889         114\n",
            "Conseils et informations produits                             0.8987      0.9103      0.9045          78\n",
            "Engagements, événements et initiatives                        0.9850      0.9493      0.9668         138\n",
            "Services exclusifs, programmes et personnalisations           0.9353      0.9353      0.9353         340\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "                                                             Assistance technique et support immédiat                   Commandes, livraison et suivi                      Conseils et informations produits                 Engagements, événements et initiatives         Services exclusifs, programmes et personnalisations \n",
            "Assistance technique et support immédiat                                      37                                                    0                                                    0                                                    0                                                    3                          \n",
            "Commandes, livraison et suivi                                                  0                                                   104                                                   0                                                    0                                                   10                          \n",
            "Conseils et informations produits                                              0                                                    0                                                   71                                                    0                                                    7                          \n",
            "Engagements, événements et initiatives                                         0                                                    0                                                    5                                                   131                                                   2                          \n",
            "Services exclusifs, programmes et personnalisations                            1                                                   16                                                    3                                                    2                                                   318                         \n",
            "Elapsed time: 00:13:02\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Define a custom classification head\n",
        "head_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels},\n",
        "    ]\n",
        "\n",
        "# Create Classification Model from \"Camembert-base\"\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"camembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=head_layer_configs\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                     labels_names=labels_names,\n",
        "                     )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv_PLYLXYZCD"
      },
      "source": [
        "### Use AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg-9u0LbYZCD",
        "outputId": "1d609f51-4d86-4661-ec51-6a8b3fc842da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 1.3326, Val Loss: 1.1319, Val MCC: 0.4692, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 0.8206, Val Loss: 0.8275, Val MCC: 0.6353, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.5458, Val Loss: 0.5490, Val MCC: 0.7632, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.3644, Val Loss: 0.4060, Val MCC: 0.8193, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.2526, Val Loss: 0.3247, Val MCC: 0.8441, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.1851, Val Loss: 0.2847, Val MCC: 0.8629, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.1469, Val Loss: 0.2835, Val MCC: 0.8625, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.1113, Val Loss: 0.2829, Val MCC: 0.8811, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.0884, Val Loss: 0.2654, Val MCC: 0.8944, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.0799, Val Loss: 0.2702, Val MCC: 0.8987, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.0552, Val Loss: 0.3107, Val MCC: 0.8910, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.0505, Val Loss: 0.3370, Val MCC: 0.8791, lr: 1.000e-05\n",
            "Best epoch: 8, Best loss: 0.2654\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9268\n",
            " - f1_macro: 0.9265\n",
            " - f1_micro: 0.9268\n",
            " - f1_weighted: 0.9271\n",
            " - mcc: 0.8944\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class                                                      Precision      Recall          F1     Support\n",
            "Assistance technique et support immédiat                      1.0000      0.9500      0.9744          40\n",
            "Commandes, livraison et suivi                                 0.8480      0.9298      0.8870         114\n",
            "Conseils et informations produits                             0.8933      0.8590      0.8758          78\n",
            "Engagements, événements et initiatives                        0.9776      0.9493      0.9632         138\n",
            "Services exclusifs, programmes et personnalisations           0.9349      0.9294      0.9322         340\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "                                                             Assistance technique et support immédiat                   Commandes, livraison et suivi                      Conseils et informations produits                 Engagements, événements et initiatives         Services exclusifs, programmes et personnalisations \n",
            "Assistance technique et support immédiat                                      38                                                    0                                                    0                                                    0                                                    2                          \n",
            "Commandes, livraison et suivi                                                  0                                                   106                                                   1                                                    0                                                    7                          \n",
            "Conseils et informations produits                                              0                                                    0                                                   67                                                    0                                                   11                          \n",
            "Engagements, événements et initiatives                                         0                                                    0                                                    5                                                   131                                                   2                          \n",
            "Services exclusifs, programmes et personnalisations                            0                                                   19                                                    2                                                    3                                                   316                         \n",
            "Elapsed time: 00:10:41\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Define a custom classification head\n",
        "head_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels},\n",
        "    ]\n",
        "\n",
        "# Create Classification Model from \"Camembert-base\"\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"camembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=head_layer_configs\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                    labels_names=labels_names,\n",
        "                    optimizer_class=AdamW\n",
        "                    )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9arqXYHYZCD"
      },
      "source": [
        "### Add a Lora configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yo2LrxYYZCD",
        "outputId": "86f4774d-b716-47c7-c39e-11bbe357cf72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Using Lora\n",
            "Target modules : ['base_model.encoder.layer.0.attention.self.query', 'base_model.encoder.layer.0.attention.self.key', 'base_model.encoder.layer.0.attention.output.dense', 'base_model.encoder.layer.0.intermediate.dense', 'base_model.encoder.layer.0.output.dense', 'base_model.encoder.layer.1.attention.self.query', 'base_model.encoder.layer.1.attention.self.key', 'base_model.encoder.layer.1.attention.output.dense', 'base_model.encoder.layer.1.intermediate.dense', 'base_model.encoder.layer.1.output.dense', 'base_model.encoder.layer.2.attention.self.query', 'base_model.encoder.layer.2.attention.self.key', 'base_model.encoder.layer.2.attention.output.dense', 'base_model.encoder.layer.2.intermediate.dense', 'base_model.encoder.layer.2.output.dense', 'base_model.encoder.layer.3.attention.self.query', 'base_model.encoder.layer.3.attention.self.key', 'base_model.encoder.layer.3.attention.output.dense', 'base_model.encoder.layer.3.intermediate.dense', 'base_model.encoder.layer.3.output.dense', 'base_model.encoder.layer.4.attention.self.query', 'base_model.encoder.layer.4.attention.self.key', 'base_model.encoder.layer.4.attention.output.dense', 'base_model.encoder.layer.4.intermediate.dense', 'base_model.encoder.layer.4.output.dense', 'base_model.encoder.layer.5.attention.self.query', 'base_model.encoder.layer.5.attention.self.key', 'base_model.encoder.layer.5.attention.output.dense', 'base_model.encoder.layer.5.intermediate.dense', 'base_model.encoder.layer.5.output.dense', 'base_model.encoder.layer.6.attention.self.query', 'base_model.encoder.layer.6.attention.self.key', 'base_model.encoder.layer.6.attention.output.dense', 'base_model.encoder.layer.6.intermediate.dense', 'base_model.encoder.layer.6.output.dense', 'base_model.encoder.layer.7.attention.self.query', 'base_model.encoder.layer.7.attention.self.key', 'base_model.encoder.layer.7.attention.output.dense', 'base_model.encoder.layer.7.intermediate.dense', 'base_model.encoder.layer.7.output.dense', 'base_model.encoder.layer.8.attention.self.query', 'base_model.encoder.layer.8.attention.self.key', 'base_model.encoder.layer.8.attention.output.dense', 'base_model.encoder.layer.8.intermediate.dense', 'base_model.encoder.layer.8.output.dense', 'base_model.encoder.layer.9.attention.self.query', 'base_model.encoder.layer.9.attention.self.key', 'base_model.encoder.layer.9.attention.output.dense', 'base_model.encoder.layer.9.intermediate.dense', 'base_model.encoder.layer.9.output.dense', 'base_model.encoder.layer.10.attention.self.query', 'base_model.encoder.layer.10.attention.self.key', 'base_model.encoder.layer.10.attention.output.dense', 'base_model.encoder.layer.10.intermediate.dense', 'base_model.encoder.layer.10.output.dense', 'base_model.encoder.layer.11.attention.self.query', 'base_model.encoder.layer.11.attention.self.key', 'base_model.encoder.layer.11.attention.output.dense', 'base_model.encoder.layer.11.intermediate.dense', 'base_model.encoder.layer.11.output.dense', 'base_model.pooler.dense']\n",
            "trainable params: 10591242 || all params: 121213194 || trainable%: 8.737697317009896\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 1.5494, Val Loss: 1.4124, Val MCC: 0.3102, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 1.2974, Val Loss: 1.1852, Val MCC: 0.4326, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 1.0313, Val Loss: 1.0716, Val MCC: 0.4857, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.8454, Val Loss: 0.9470, Val MCC: 0.5517, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.7188, Val Loss: 0.8482, Val MCC: 0.5982, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.6175, Val Loss: 0.7592, Val MCC: 0.6375, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.5357, Val Loss: 0.6959, Val MCC: 0.6644, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.4733, Val Loss: 0.6143, Val MCC: 0.7081, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.4151, Val Loss: 0.5486, Val MCC: 0.7383, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.3515, Val Loss: 0.4647, Val MCC: 0.7683, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.3141, Val Loss: 0.4243, Val MCC: 0.7941, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.2799, Val Loss: 0.3831, Val MCC: 0.8249, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.2445, Val Loss: 0.3584, Val MCC: 0.8259, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.2170, Val Loss: 0.3635, Val MCC: 0.8263, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.1928, Val Loss: 0.3577, Val MCC: 0.8243, lr: 1.000e-05\n",
            "Epoch 15/29, Train Loss: 0.1669, Val Loss: 0.2805, Val MCC: 0.8654, lr: 1.000e-05\n",
            "Epoch 16/29, Train Loss: 0.1541, Val Loss: 0.2927, Val MCC: 0.8619, lr: 1.000e-05\n",
            "Epoch 17/29, Train Loss: 0.1383, Val Loss: 0.2849, Val MCC: 0.8659, lr: 1.000e-05\n",
            "Epoch 18/29, Train Loss: 0.1275, Val Loss: 0.3335, Val MCC: 0.8654, lr: 1.000e-05\n",
            "Best epoch: 15, Best loss: 0.2805\n",
            "\n",
            "\n",
            "** Global metrics :\n",
            "\n",
            " - accuracy: 0.9028\n",
            " - f1_macro: 0.8957\n",
            " - f1_micro: 0.9028\n",
            " - f1_weighted: 0.9036\n",
            " - mcc: 0.8654\n",
            "\n",
            "\n",
            "** Per-Classes metrics :\n",
            "\n",
            "Class                                                      Precision      Recall          F1     Support\n",
            "Assistance technique et support immédiat                      0.7800      0.9750      0.8667          40\n",
            "Commandes, livraison et suivi                                 0.8168      0.9386      0.8735         114\n",
            "Conseils et informations produits                             0.8409      0.9487      0.8916          78\n",
            "Engagements, événements et initiatives                        0.9485      0.9348      0.9416         138\n",
            "Services exclusifs, programmes et personnalisations           0.9574      0.8588      0.9054         340\n",
            "\n",
            "\n",
            "** Confusion Matrix (FN/Row - FP/Col):\n",
            "\n",
            "                                                             Assistance technique et support immédiat                   Commandes, livraison et suivi                      Conseils et informations produits                 Engagements, événements et initiatives         Services exclusifs, programmes et personnalisations \n",
            "Assistance technique et support immédiat                                      39                                                    0                                                    0                                                    0                                                    1                          \n",
            "Commandes, livraison et suivi                                                  0                                                   107                                                   1                                                    0                                                    6                          \n",
            "Conseils et informations produits                                              0                                                    0                                                   74                                                    0                                                    4                          \n",
            "Engagements, événements et initiatives                                         1                                                    0                                                    6                                                   129                                                   2                          \n",
            "Services exclusifs, programmes et personnalisations                           10                                                   24                                                    7                                                    7                                                   292                         \n",
            "Elapsed time: 00:14:47\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "val_size = 0.3\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Define a custom classification head\n",
        "head_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels},\n",
        "    ]\n",
        "\n",
        "# Create Classification Model from \"Camembert-base\"\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"camembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=head_layer_configs\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                            labels_names=labels_names,\n",
        "                            optimizer_class=AdamW,\n",
        "                            use_lora=True,\n",
        "                            lora_r = 64,\n",
        "                            lora_alpha= 128,\n",
        "                            lora_dropout = 0.01,\n",
        "                            )\n",
        "\n",
        "# Train over a Holdout with Earlystopping\n",
        "ret = trainer.holdout(texts=texts,\n",
        "                    labels=labels,\n",
        "                    val_size=val_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    patience=patience,\n",
        "                    min_delta=min_delta,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTWZRBmLYZCE"
      },
      "source": [
        "## Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPzP053cYZCE",
        "outputId": "43458de4-1b82-460b-f606-2a4a889669e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "\n",
            "\n",
            "> Fold 1\n",
            "Using Lora\n",
            "Target modules : ['base_model.encoder.layer.0.attention.self.query', 'base_model.encoder.layer.0.attention.self.key', 'base_model.encoder.layer.0.attention.output.dense', 'base_model.encoder.layer.0.intermediate.dense', 'base_model.encoder.layer.0.output.dense', 'base_model.encoder.layer.1.attention.self.query', 'base_model.encoder.layer.1.attention.self.key', 'base_model.encoder.layer.1.attention.output.dense', 'base_model.encoder.layer.1.intermediate.dense', 'base_model.encoder.layer.1.output.dense', 'base_model.encoder.layer.2.attention.self.query', 'base_model.encoder.layer.2.attention.self.key', 'base_model.encoder.layer.2.attention.output.dense', 'base_model.encoder.layer.2.intermediate.dense', 'base_model.encoder.layer.2.output.dense', 'base_model.encoder.layer.3.attention.self.query', 'base_model.encoder.layer.3.attention.self.key', 'base_model.encoder.layer.3.attention.output.dense', 'base_model.encoder.layer.3.intermediate.dense', 'base_model.encoder.layer.3.output.dense', 'base_model.encoder.layer.4.attention.self.query', 'base_model.encoder.layer.4.attention.self.key', 'base_model.encoder.layer.4.attention.output.dense', 'base_model.encoder.layer.4.intermediate.dense', 'base_model.encoder.layer.4.output.dense', 'base_model.encoder.layer.5.attention.self.query', 'base_model.encoder.layer.5.attention.self.key', 'base_model.encoder.layer.5.attention.output.dense', 'base_model.encoder.layer.5.intermediate.dense', 'base_model.encoder.layer.5.output.dense', 'base_model.encoder.layer.6.attention.self.query', 'base_model.encoder.layer.6.attention.self.key', 'base_model.encoder.layer.6.attention.output.dense', 'base_model.encoder.layer.6.intermediate.dense', 'base_model.encoder.layer.6.output.dense', 'base_model.encoder.layer.7.attention.self.query', 'base_model.encoder.layer.7.attention.self.key', 'base_model.encoder.layer.7.attention.output.dense', 'base_model.encoder.layer.7.intermediate.dense', 'base_model.encoder.layer.7.output.dense', 'base_model.encoder.layer.8.attention.self.query', 'base_model.encoder.layer.8.attention.self.key', 'base_model.encoder.layer.8.attention.output.dense', 'base_model.encoder.layer.8.intermediate.dense', 'base_model.encoder.layer.8.output.dense', 'base_model.encoder.layer.9.attention.self.query', 'base_model.encoder.layer.9.attention.self.key', 'base_model.encoder.layer.9.attention.output.dense', 'base_model.encoder.layer.9.intermediate.dense', 'base_model.encoder.layer.9.output.dense', 'base_model.encoder.layer.10.attention.self.query', 'base_model.encoder.layer.10.attention.self.key', 'base_model.encoder.layer.10.attention.output.dense', 'base_model.encoder.layer.10.intermediate.dense', 'base_model.encoder.layer.10.output.dense', 'base_model.encoder.layer.11.attention.self.query', 'base_model.encoder.layer.11.attention.self.key', 'base_model.encoder.layer.11.attention.output.dense', 'base_model.encoder.layer.11.intermediate.dense', 'base_model.encoder.layer.11.output.dense', 'base_model.pooler.dense']\n",
            "trainable params: 10591242 || all params: 121213194 || trainable%: 8.737697317009896\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 1.5547, Val Loss: 1.3331, Val MCC: 0.3924, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 1.2773, Val Loss: 1.1052, Val MCC: 0.4910, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 1.0021, Val Loss: 0.9762, Val MCC: 0.5272, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.8304, Val Loss: 0.8790, Val MCC: 0.5469, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.6929, Val Loss: 0.7769, Val MCC: 0.5935, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.5985, Val Loss: 0.6893, Val MCC: 0.6605, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.5108, Val Loss: 0.5944, Val MCC: 0.6991, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.4578, Val Loss: 0.5403, Val MCC: 0.7395, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.4008, Val Loss: 0.4930, Val MCC: 0.7660, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.3604, Val Loss: 0.4548, Val MCC: 0.7764, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.3192, Val Loss: 0.4445, Val MCC: 0.7847, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.2847, Val Loss: 0.4103, Val MCC: 0.7977, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.2682, Val Loss: 0.4329, Val MCC: 0.7928, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.2384, Val Loss: 0.4173, Val MCC: 0.7974, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.2218, Val Loss: 0.3535, Val MCC: 0.8316, lr: 1.000e-05\n",
            "Epoch 15/29, Train Loss: 0.2030, Val Loss: 0.3060, Val MCC: 0.8653, lr: 1.000e-05\n",
            "Epoch 16/29, Train Loss: 0.1861, Val Loss: 0.3562, Val MCC: 0.8306, lr: 1.000e-05\n",
            "Epoch 17/29, Train Loss: 0.1684, Val Loss: 0.2470, Val MCC: 0.8951, lr: 1.000e-05\n",
            "Epoch 18/29, Train Loss: 0.1537, Val Loss: 0.3284, Val MCC: 0.8545, lr: 1.000e-05\n",
            "Epoch 19/29, Train Loss: 0.1384, Val Loss: 0.2633, Val MCC: 0.8899, lr: 1.000e-05\n",
            "Epoch 20/29, Train Loss: 0.1327, Val Loss: 0.2845, Val MCC: 0.8551, lr: 1.000e-05\n",
            "Best epoch: 17, Best loss: 0.2470\n",
            "\n",
            "\n",
            "> Fold 2\n",
            "Using Lora\n",
            "Target modules : ['roberta.encoder.layer.0.attention.self.query', 'roberta.encoder.layer.0.attention.self.key', 'roberta.encoder.layer.0.attention.output.dense', 'roberta.encoder.layer.0.intermediate.dense', 'roberta.encoder.layer.0.output.dense', 'roberta.encoder.layer.1.attention.self.query', 'roberta.encoder.layer.1.attention.self.key', 'roberta.encoder.layer.1.attention.output.dense', 'roberta.encoder.layer.1.intermediate.dense', 'roberta.encoder.layer.1.output.dense', 'roberta.encoder.layer.2.attention.self.query', 'roberta.encoder.layer.2.attention.self.key', 'roberta.encoder.layer.2.attention.output.dense', 'roberta.encoder.layer.2.intermediate.dense', 'roberta.encoder.layer.2.output.dense', 'roberta.encoder.layer.3.attention.self.query', 'roberta.encoder.layer.3.attention.self.key', 'roberta.encoder.layer.3.attention.output.dense', 'roberta.encoder.layer.3.intermediate.dense', 'roberta.encoder.layer.3.output.dense', 'roberta.encoder.layer.4.attention.self.query', 'roberta.encoder.layer.4.attention.self.key', 'roberta.encoder.layer.4.attention.output.dense', 'roberta.encoder.layer.4.intermediate.dense', 'roberta.encoder.layer.4.output.dense', 'roberta.encoder.layer.5.attention.self.query', 'roberta.encoder.layer.5.attention.self.key', 'roberta.encoder.layer.5.attention.output.dense', 'roberta.encoder.layer.5.intermediate.dense', 'roberta.encoder.layer.5.output.dense', 'roberta.encoder.layer.6.attention.self.query', 'roberta.encoder.layer.6.attention.self.key', 'roberta.encoder.layer.6.attention.output.dense', 'roberta.encoder.layer.6.intermediate.dense', 'roberta.encoder.layer.6.output.dense', 'roberta.encoder.layer.7.attention.self.query', 'roberta.encoder.layer.7.attention.self.key', 'roberta.encoder.layer.7.attention.output.dense', 'roberta.encoder.layer.7.intermediate.dense', 'roberta.encoder.layer.7.output.dense', 'roberta.encoder.layer.8.attention.self.query', 'roberta.encoder.layer.8.attention.self.key', 'roberta.encoder.layer.8.attention.output.dense', 'roberta.encoder.layer.8.intermediate.dense', 'roberta.encoder.layer.8.output.dense', 'roberta.encoder.layer.9.attention.self.query', 'roberta.encoder.layer.9.attention.self.key', 'roberta.encoder.layer.9.attention.output.dense', 'roberta.encoder.layer.9.intermediate.dense', 'roberta.encoder.layer.9.output.dense', 'roberta.encoder.layer.10.attention.self.query', 'roberta.encoder.layer.10.attention.self.key', 'roberta.encoder.layer.10.attention.output.dense', 'roberta.encoder.layer.10.intermediate.dense', 'roberta.encoder.layer.10.output.dense', 'roberta.encoder.layer.11.attention.self.query', 'roberta.encoder.layer.11.attention.self.key', 'roberta.encoder.layer.11.attention.output.dense', 'roberta.encoder.layer.11.intermediate.dense', 'roberta.encoder.layer.11.output.dense', 'classifier.dense']\n",
            "trainable params: 10822666 || all params: 120854026 || trainable%: 8.955155536150695\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 1.5878, Val Loss: 1.4881, Val MCC: 0.2234, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 1.3514, Val Loss: 1.2110, Val MCC: 0.4446, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.9294, Val Loss: 0.9540, Val MCC: 0.5013, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.6591, Val Loss: 0.7512, Val MCC: 0.6060, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.5053, Val Loss: 0.6256, Val MCC: 0.6873, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.4100, Val Loss: 0.5163, Val MCC: 0.7597, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.3563, Val Loss: 0.4165, Val MCC: 0.8030, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.2834, Val Loss: 0.4444, Val MCC: 0.8030, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.2497, Val Loss: 0.3848, Val MCC: 0.8298, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.2159, Val Loss: 0.3592, Val MCC: 0.8196, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1812, Val Loss: 0.3879, Val MCC: 0.8310, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.1672, Val Loss: 0.3535, Val MCC: 0.8581, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.1565, Val Loss: 0.3245, Val MCC: 0.8697, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.1415, Val Loss: 0.3811, Val MCC: 0.8552, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.1354, Val Loss: 0.3581, Val MCC: 0.8798, lr: 1.000e-05\n",
            "Epoch 15/29, Train Loss: 0.1225, Val Loss: 0.3431, Val MCC: 0.8830, lr: 1.000e-05\n",
            "Best epoch: 12, Best loss: 0.3245\n",
            "\n",
            "\n",
            "> Fold 3\n",
            "Using Lora\n",
            "Target modules : ['roberta.encoder.layer.0.attention.self.query', 'roberta.encoder.layer.0.attention.self.key', 'roberta.encoder.layer.0.attention.output.dense', 'roberta.encoder.layer.0.intermediate.dense', 'roberta.encoder.layer.0.output.dense', 'roberta.encoder.layer.1.attention.self.query', 'roberta.encoder.layer.1.attention.self.key', 'roberta.encoder.layer.1.attention.output.dense', 'roberta.encoder.layer.1.intermediate.dense', 'roberta.encoder.layer.1.output.dense', 'roberta.encoder.layer.2.attention.self.query', 'roberta.encoder.layer.2.attention.self.key', 'roberta.encoder.layer.2.attention.output.dense', 'roberta.encoder.layer.2.intermediate.dense', 'roberta.encoder.layer.2.output.dense', 'roberta.encoder.layer.3.attention.self.query', 'roberta.encoder.layer.3.attention.self.key', 'roberta.encoder.layer.3.attention.output.dense', 'roberta.encoder.layer.3.intermediate.dense', 'roberta.encoder.layer.3.output.dense', 'roberta.encoder.layer.4.attention.self.query', 'roberta.encoder.layer.4.attention.self.key', 'roberta.encoder.layer.4.attention.output.dense', 'roberta.encoder.layer.4.intermediate.dense', 'roberta.encoder.layer.4.output.dense', 'roberta.encoder.layer.5.attention.self.query', 'roberta.encoder.layer.5.attention.self.key', 'roberta.encoder.layer.5.attention.output.dense', 'roberta.encoder.layer.5.intermediate.dense', 'roberta.encoder.layer.5.output.dense', 'roberta.encoder.layer.6.attention.self.query', 'roberta.encoder.layer.6.attention.self.key', 'roberta.encoder.layer.6.attention.output.dense', 'roberta.encoder.layer.6.intermediate.dense', 'roberta.encoder.layer.6.output.dense', 'roberta.encoder.layer.7.attention.self.query', 'roberta.encoder.layer.7.attention.self.key', 'roberta.encoder.layer.7.attention.output.dense', 'roberta.encoder.layer.7.intermediate.dense', 'roberta.encoder.layer.7.output.dense', 'roberta.encoder.layer.8.attention.self.query', 'roberta.encoder.layer.8.attention.self.key', 'roberta.encoder.layer.8.attention.output.dense', 'roberta.encoder.layer.8.intermediate.dense', 'roberta.encoder.layer.8.output.dense', 'roberta.encoder.layer.9.attention.self.query', 'roberta.encoder.layer.9.attention.self.key', 'roberta.encoder.layer.9.attention.output.dense', 'roberta.encoder.layer.9.intermediate.dense', 'roberta.encoder.layer.9.output.dense', 'roberta.encoder.layer.10.attention.self.query', 'roberta.encoder.layer.10.attention.self.key', 'roberta.encoder.layer.10.attention.output.dense', 'roberta.encoder.layer.10.intermediate.dense', 'roberta.encoder.layer.10.output.dense', 'roberta.encoder.layer.11.attention.self.query', 'roberta.encoder.layer.11.attention.self.key', 'roberta.encoder.layer.11.attention.output.dense', 'roberta.encoder.layer.11.intermediate.dense', 'roberta.encoder.layer.11.output.dense', 'classifier.dense']\n",
            "trainable params: 10822666 || all params: 120854026 || trainable%: 8.955155536150695\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 1.5911, Val Loss: 1.5027, Val MCC: 0.3736, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 1.3614, Val Loss: 1.2607, Val MCC: 0.4382, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.9459, Val Loss: 1.0231, Val MCC: 0.5094, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.6570, Val Loss: 0.8681, Val MCC: 0.5928, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.5067, Val Loss: 0.7760, Val MCC: 0.6206, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.4090, Val Loss: 0.6714, Val MCC: 0.6694, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.3607, Val Loss: 0.6280, Val MCC: 0.7007, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.2933, Val Loss: 0.5536, Val MCC: 0.7365, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.2618, Val Loss: 0.5163, Val MCC: 0.7602, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.2270, Val Loss: 0.4455, Val MCC: 0.7940, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1963, Val Loss: 0.4452, Val MCC: 0.7904, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.1694, Val Loss: 0.4254, Val MCC: 0.8020, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.1548, Val Loss: 0.4072, Val MCC: 0.8167, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.1304, Val Loss: 0.4247, Val MCC: 0.8145, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.1176, Val Loss: 0.4617, Val MCC: 0.8142, lr: 1.000e-05\n",
            "Epoch 15/29, Train Loss: 0.1267, Val Loss: 0.3743, Val MCC: 0.8208, lr: 1.000e-05\n",
            "Epoch 16/29, Train Loss: 0.1005, Val Loss: 0.3981, Val MCC: 0.8074, lr: 1.000e-05\n",
            "Epoch 17/29, Train Loss: 0.0907, Val Loss: 0.3770, Val MCC: 0.8334, lr: 1.000e-05\n",
            "Epoch 18/29, Train Loss: 0.0928, Val Loss: 0.3751, Val MCC: 0.8594, lr: 1.000e-05\n",
            "Best epoch: 15, Best loss: 0.3743\n",
            "\n",
            "\n",
            "> Fold 4\n",
            "Using Lora\n",
            "Target modules : ['roberta.encoder.layer.0.attention.self.query', 'roberta.encoder.layer.0.attention.self.key', 'roberta.encoder.layer.0.attention.output.dense', 'roberta.encoder.layer.0.intermediate.dense', 'roberta.encoder.layer.0.output.dense', 'roberta.encoder.layer.1.attention.self.query', 'roberta.encoder.layer.1.attention.self.key', 'roberta.encoder.layer.1.attention.output.dense', 'roberta.encoder.layer.1.intermediate.dense', 'roberta.encoder.layer.1.output.dense', 'roberta.encoder.layer.2.attention.self.query', 'roberta.encoder.layer.2.attention.self.key', 'roberta.encoder.layer.2.attention.output.dense', 'roberta.encoder.layer.2.intermediate.dense', 'roberta.encoder.layer.2.output.dense', 'roberta.encoder.layer.3.attention.self.query', 'roberta.encoder.layer.3.attention.self.key', 'roberta.encoder.layer.3.attention.output.dense', 'roberta.encoder.layer.3.intermediate.dense', 'roberta.encoder.layer.3.output.dense', 'roberta.encoder.layer.4.attention.self.query', 'roberta.encoder.layer.4.attention.self.key', 'roberta.encoder.layer.4.attention.output.dense', 'roberta.encoder.layer.4.intermediate.dense', 'roberta.encoder.layer.4.output.dense', 'roberta.encoder.layer.5.attention.self.query', 'roberta.encoder.layer.5.attention.self.key', 'roberta.encoder.layer.5.attention.output.dense', 'roberta.encoder.layer.5.intermediate.dense', 'roberta.encoder.layer.5.output.dense', 'roberta.encoder.layer.6.attention.self.query', 'roberta.encoder.layer.6.attention.self.key', 'roberta.encoder.layer.6.attention.output.dense', 'roberta.encoder.layer.6.intermediate.dense', 'roberta.encoder.layer.6.output.dense', 'roberta.encoder.layer.7.attention.self.query', 'roberta.encoder.layer.7.attention.self.key', 'roberta.encoder.layer.7.attention.output.dense', 'roberta.encoder.layer.7.intermediate.dense', 'roberta.encoder.layer.7.output.dense', 'roberta.encoder.layer.8.attention.self.query', 'roberta.encoder.layer.8.attention.self.key', 'roberta.encoder.layer.8.attention.output.dense', 'roberta.encoder.layer.8.intermediate.dense', 'roberta.encoder.layer.8.output.dense', 'roberta.encoder.layer.9.attention.self.query', 'roberta.encoder.layer.9.attention.self.key', 'roberta.encoder.layer.9.attention.output.dense', 'roberta.encoder.layer.9.intermediate.dense', 'roberta.encoder.layer.9.output.dense', 'roberta.encoder.layer.10.attention.self.query', 'roberta.encoder.layer.10.attention.self.key', 'roberta.encoder.layer.10.attention.output.dense', 'roberta.encoder.layer.10.intermediate.dense', 'roberta.encoder.layer.10.output.dense', 'roberta.encoder.layer.11.attention.self.query', 'roberta.encoder.layer.11.attention.self.key', 'roberta.encoder.layer.11.attention.output.dense', 'roberta.encoder.layer.11.intermediate.dense', 'roberta.encoder.layer.11.output.dense', 'classifier.dense']\n",
            "trainable params: 10822666 || all params: 120854026 || trainable%: 8.955155536150695\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 1.5916, Val Loss: 1.5033, Val MCC: 0.3448, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 1.3637, Val Loss: 1.2259, Val MCC: 0.4808, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.9349, Val Loss: 0.9648, Val MCC: 0.5419, lr: 1.000e-05\n",
            "Epoch 3/29, Train Loss: 0.6468, Val Loss: 0.8048, Val MCC: 0.6343, lr: 1.000e-05\n",
            "Epoch 4/29, Train Loss: 0.5044, Val Loss: 0.7152, Val MCC: 0.6789, lr: 1.000e-05\n",
            "Epoch 5/29, Train Loss: 0.4166, Val Loss: 0.5827, Val MCC: 0.7293, lr: 1.000e-05\n",
            "Epoch 6/29, Train Loss: 0.3505, Val Loss: 0.4863, Val MCC: 0.7621, lr: 1.000e-05\n",
            "Epoch 7/29, Train Loss: 0.2858, Val Loss: 0.4377, Val MCC: 0.7905, lr: 1.000e-05\n",
            "Epoch 8/29, Train Loss: 0.2528, Val Loss: 0.4038, Val MCC: 0.8074, lr: 1.000e-05\n",
            "Epoch 9/29, Train Loss: 0.2059, Val Loss: 0.3463, Val MCC: 0.8321, lr: 1.000e-05\n",
            "Epoch 10/29, Train Loss: 0.1948, Val Loss: 0.3566, Val MCC: 0.8395, lr: 1.000e-05\n",
            "Epoch 11/29, Train Loss: 0.1681, Val Loss: 0.3541, Val MCC: 0.8509, lr: 1.000e-05\n",
            "Epoch 12/29, Train Loss: 0.1628, Val Loss: 0.2892, Val MCC: 0.8669, lr: 1.000e-05\n",
            "Epoch 13/29, Train Loss: 0.1498, Val Loss: 0.3139, Val MCC: 0.8684, lr: 1.000e-05\n",
            "Epoch 14/29, Train Loss: 0.1305, Val Loss: 0.3032, Val MCC: 0.8764, lr: 1.000e-05\n",
            "Epoch 15/29, Train Loss: 0.1222, Val Loss: 0.3035, Val MCC: 0.8742, lr: 1.000e-05\n",
            "Best epoch: 12, Best loss: 0.2892\n",
            "\n",
            "\n",
            "> Fold 5\n",
            "Using Lora\n",
            "Target modules : ['roberta.encoder.layer.0.attention.self.query', 'roberta.encoder.layer.0.attention.self.key', 'roberta.encoder.layer.0.attention.output.dense', 'roberta.encoder.layer.0.intermediate.dense', 'roberta.encoder.layer.0.output.dense', 'roberta.encoder.layer.1.attention.self.query', 'roberta.encoder.layer.1.attention.self.key', 'roberta.encoder.layer.1.attention.output.dense', 'roberta.encoder.layer.1.intermediate.dense', 'roberta.encoder.layer.1.output.dense', 'roberta.encoder.layer.2.attention.self.query', 'roberta.encoder.layer.2.attention.self.key', 'roberta.encoder.layer.2.attention.output.dense', 'roberta.encoder.layer.2.intermediate.dense', 'roberta.encoder.layer.2.output.dense', 'roberta.encoder.layer.3.attention.self.query', 'roberta.encoder.layer.3.attention.self.key', 'roberta.encoder.layer.3.attention.output.dense', 'roberta.encoder.layer.3.intermediate.dense', 'roberta.encoder.layer.3.output.dense', 'roberta.encoder.layer.4.attention.self.query', 'roberta.encoder.layer.4.attention.self.key', 'roberta.encoder.layer.4.attention.output.dense', 'roberta.encoder.layer.4.intermediate.dense', 'roberta.encoder.layer.4.output.dense', 'roberta.encoder.layer.5.attention.self.query', 'roberta.encoder.layer.5.attention.self.key', 'roberta.encoder.layer.5.attention.output.dense', 'roberta.encoder.layer.5.intermediate.dense', 'roberta.encoder.layer.5.output.dense', 'roberta.encoder.layer.6.attention.self.query', 'roberta.encoder.layer.6.attention.self.key', 'roberta.encoder.layer.6.attention.output.dense', 'roberta.encoder.layer.6.intermediate.dense', 'roberta.encoder.layer.6.output.dense', 'roberta.encoder.layer.7.attention.self.query', 'roberta.encoder.layer.7.attention.self.key', 'roberta.encoder.layer.7.attention.output.dense', 'roberta.encoder.layer.7.intermediate.dense', 'roberta.encoder.layer.7.output.dense', 'roberta.encoder.layer.8.attention.self.query', 'roberta.encoder.layer.8.attention.self.key', 'roberta.encoder.layer.8.attention.output.dense', 'roberta.encoder.layer.8.intermediate.dense', 'roberta.encoder.layer.8.output.dense', 'roberta.encoder.layer.9.attention.self.query', 'roberta.encoder.layer.9.attention.self.key', 'roberta.encoder.layer.9.attention.output.dense', 'roberta.encoder.layer.9.intermediate.dense', 'roberta.encoder.layer.9.output.dense', 'roberta.encoder.layer.10.attention.self.query', 'roberta.encoder.layer.10.attention.self.key', 'roberta.encoder.layer.10.attention.output.dense', 'roberta.encoder.layer.10.intermediate.dense', 'roberta.encoder.layer.10.output.dense', 'roberta.encoder.layer.11.attention.self.query', 'roberta.encoder.layer.11.attention.self.key', 'roberta.encoder.layer.11.attention.output.dense', 'roberta.encoder.layer.11.intermediate.dense', 'roberta.encoder.layer.11.output.dense', 'classifier.dense']\n",
            "trainable params: 10822666 || all params: 120854026 || trainable%: 8.955155536150695\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/29, Train Loss: 1.5891, Val Loss: 1.4894, Val MCC: 0.2804, lr: 1.000e-05\n",
            "Epoch 1/29, Train Loss: 1.3701, Val Loss: 1.2274, Val MCC: 0.4656, lr: 1.000e-05\n",
            "Epoch 2/29, Train Loss: 0.9551, Val Loss: 0.9895, Val MCC: 0.5277, lr: 1.000e-05\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "batch_size = 8\n",
        "patience = 3\n",
        "min_delta = 0.001\n",
        "n_splits = 5\n",
        "\n",
        "# Get number of classes to predict\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Define a custom classification head\n",
        "head_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels},\n",
        "    ]\n",
        "\n",
        "# Create Classification Model from \"Camembert-base\"\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"camembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=head_layer_configs\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                            labels_names=labels_names,\n",
        "                            optimizer_class=AdamW,\n",
        "                            use_lora=True,\n",
        "                            lora_r = 64,\n",
        "                            lora_alpha= 128,\n",
        "                            lora_dropout = 0.01,\n",
        "                            )\n",
        "\n",
        "# Cross validate with Earlystopping\n",
        "rets = trainer.cross_validation(texts=texts,\n",
        "              labels=labels,\n",
        "              n_splits=n_splits,\n",
        "              num_epochs=num_epochs,\n",
        "              batch_size=batch_size,\n",
        "              patience=patience,\n",
        "              min_delta=min_delta,\n",
        "              balanced=True)\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YrCUgdZYZCE"
      },
      "source": [
        "## Full Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oz6n1tqYZCE",
        "outputId": "62e1c3af-580a-4231-8d05-6de8a52c58ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device : cuda\n",
            "Using Lora\n",
            "Target modules : ['base_model.encoder.layer.0.attention.self.query', 'base_model.encoder.layer.0.attention.self.key', 'base_model.encoder.layer.0.attention.output.dense', 'base_model.encoder.layer.0.intermediate.dense', 'base_model.encoder.layer.0.output.dense', 'base_model.encoder.layer.1.attention.self.query', 'base_model.encoder.layer.1.attention.self.key', 'base_model.encoder.layer.1.attention.output.dense', 'base_model.encoder.layer.1.intermediate.dense', 'base_model.encoder.layer.1.output.dense', 'base_model.encoder.layer.2.attention.self.query', 'base_model.encoder.layer.2.attention.self.key', 'base_model.encoder.layer.2.attention.output.dense', 'base_model.encoder.layer.2.intermediate.dense', 'base_model.encoder.layer.2.output.dense', 'base_model.encoder.layer.3.attention.self.query', 'base_model.encoder.layer.3.attention.self.key', 'base_model.encoder.layer.3.attention.output.dense', 'base_model.encoder.layer.3.intermediate.dense', 'base_model.encoder.layer.3.output.dense', 'base_model.encoder.layer.4.attention.self.query', 'base_model.encoder.layer.4.attention.self.key', 'base_model.encoder.layer.4.attention.output.dense', 'base_model.encoder.layer.4.intermediate.dense', 'base_model.encoder.layer.4.output.dense', 'base_model.encoder.layer.5.attention.self.query', 'base_model.encoder.layer.5.attention.self.key', 'base_model.encoder.layer.5.attention.output.dense', 'base_model.encoder.layer.5.intermediate.dense', 'base_model.encoder.layer.5.output.dense', 'base_model.encoder.layer.6.attention.self.query', 'base_model.encoder.layer.6.attention.self.key', 'base_model.encoder.layer.6.attention.output.dense', 'base_model.encoder.layer.6.intermediate.dense', 'base_model.encoder.layer.6.output.dense', 'base_model.encoder.layer.7.attention.self.query', 'base_model.encoder.layer.7.attention.self.key', 'base_model.encoder.layer.7.attention.output.dense', 'base_model.encoder.layer.7.intermediate.dense', 'base_model.encoder.layer.7.output.dense', 'base_model.encoder.layer.8.attention.self.query', 'base_model.encoder.layer.8.attention.self.key', 'base_model.encoder.layer.8.attention.output.dense', 'base_model.encoder.layer.8.intermediate.dense', 'base_model.encoder.layer.8.output.dense', 'base_model.encoder.layer.9.attention.self.query', 'base_model.encoder.layer.9.attention.self.key', 'base_model.encoder.layer.9.attention.output.dense', 'base_model.encoder.layer.9.intermediate.dense', 'base_model.encoder.layer.9.output.dense', 'base_model.encoder.layer.10.attention.self.query', 'base_model.encoder.layer.10.attention.self.key', 'base_model.encoder.layer.10.attention.output.dense', 'base_model.encoder.layer.10.intermediate.dense', 'base_model.encoder.layer.10.output.dense', 'base_model.encoder.layer.11.attention.self.query', 'base_model.encoder.layer.11.attention.self.key', 'base_model.encoder.layer.11.attention.output.dense', 'base_model.encoder.layer.11.intermediate.dense', 'base_model.encoder.layer.11.output.dense', 'base_model.pooler.dense']\n",
            "trainable params: 10591242 || all params: 121213194 || trainable%: 8.737697317009896\n",
            "Use optimizer : AdamW\n",
            " - {'lr': 1e-05}\n",
            "No scheduler used\n",
            "Epoch 0/8, Training Loss: 1.5148\n",
            "Epoch 1/8, Training Loss: 1.1293\n",
            "Epoch 2/8, Training Loss: 0.8763\n",
            "Epoch 3/8, Training Loss: 0.7051\n",
            "Epoch 4/8, Training Loss: 0.5833\n",
            "Epoch 5/8, Training Loss: 0.4859\n",
            "Epoch 6/8, Training Loss: 0.4147\n",
            "Epoch 7/8, Training Loss: 0.3588\n",
            "Epoch 8/8, Training Loss: 0.3235\n",
            "Elapsed time: 00:08:03\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 9\n",
        "batch_size = 8 # 2\n",
        "train_size = 1.0 #0.15\n",
        "\n",
        "num_labels = len(labels_names)\n",
        "\n",
        "# Define a custom classification head\n",
        "head_layer_configs = [\n",
        "        {\"input_size\": 768, \"output_size\": 512, \"activation\": nn.ReLU, \"batch_norm\": True},\n",
        "        {\"input_size\": 512, \"output_size\": 256, \"activation\": nn.ReLU, \"layer_norm\": True},\n",
        "        {\"input_size\": 256, \"output_size\": num_labels},\n",
        "    ]\n",
        "\n",
        "# Create Classification Model from \"Camembert-base\"\n",
        "model = BeeMLMClassifier(\n",
        "    model_name = \"camembert-base\",\n",
        "    num_labels = num_labels,\n",
        "    head_layers=head_layer_configs\n",
        ")\n",
        "\n",
        "# Create Trainer with Lora parameters\n",
        "trainer = BeeTrainer(model=model,\n",
        "                            labels_names=labels_names,\n",
        "                            optimizer_class=AdamW,\n",
        "                            use_lora=True,\n",
        "                            lora_r = 64,\n",
        "                            lora_alpha= 128,\n",
        "                            lora_dropout = 0.01,\n",
        "                            )\n",
        "\n",
        "# Train the model\n",
        "ret = trainer.train(texts=texts,\n",
        "                    labels=labels,\n",
        "                    train_size=train_size,\n",
        "                    num_epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    balanced=True\n",
        "                    )\n",
        "\n",
        "# Save model and adaptater\n",
        "trainer.save_model(\"./model-multiclass_v1\")\n",
        "trainer.save_adaptater(\"./adaptater-multiclass_v1\")\n",
        "\n",
        "# Free CPU/GPU memory\n",
        "trainer.release_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cg03kDuYZCF"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsRAMj0gYZCF"
      },
      "source": [
        "### Reload model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffZlwIseYZCF"
      },
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "bee_mlm_model = BeeMLMClassifier.load_model_safetensors(\"./model-multiclass_v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM6WIzu9YZCF"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KvoRux3YZCF",
        "outputId": "128a7be7-2fd5-4853-d478-52c98be130e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.0421334602516051\n"
          ]
        }
      ],
      "source": [
        "y_preds = bee_mlm_model.predict(test_texts, batch_size=50, device=\"cpu\")\n",
        "mcc = matthews_corrcoef(test_labels, y_preds)\n",
        "print(mcc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppQCNA_4hOY_"
      },
      "source": [
        "# End of game"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
